{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеки, которые нам понадобятся в дальнейшем:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import Pool, CatBoostClassifier, CatBoost, cv\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import notebook\n",
    "import warnings\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортируем библиотеки для работы с текстом\n",
    "import torch, transformers, nltk, re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "\n",
      "Index(['text', 'toxic'], dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Количество пропусков:\n",
      "text     0\n",
      "toxic    0\n",
      "dtype: int64\n",
      "\n",
      "Количество дубликатов: 0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.info()\n",
    "print()\n",
    "print(data.columns)\n",
    "print()\n",
    "display(data.head())\n",
    "print()\n",
    "print('Количество пропусков:')\n",
    "print(data.isna().sum())\n",
    "print()\n",
    "print('Количество дубликатов:', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски и полные дубликаты отсутствуют. Названия столбцов прописаны адекватно.  \n",
    "Для дальнейшей обработки требуется провести лемматизацию по столбцу 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сформируем корпус текстов и осуществим кодировку:\n",
    "data['text'] = data['text'].astype('U').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим функцию для лемматизации текстов на английском языке и проверим ее работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Why the edits make under my username Hardcore Metallica Fan be revert ? They be n't vandalism , just closure on some GAs after I vote at New York Dolls FAC . And please do n't remove the template from the talk page since I 'm retire now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize with POS Tag\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "# Заявим лемматизатор\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Лемматизируем первую строку корпуса\n",
    "print(' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(data.loc[0,'text'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим полученный набор слов с помощбю регулярных выражений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Лемматизированный текст: ['Explanation', 'Why', 'the', 'edits', 'make', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'be', 'revert', '?', 'They', 'be', \"n't\", 'vandalism', ',', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'vote', 'at', 'New', 'York', 'Dolls', 'FAC', '.', 'And', 'please', 'do', \"n't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', \"'m\", 'retire', 'now.89.205.38.27']\n",
      "Очищенный и лемматизированный текст: Explanation Why the edits make under my username Hardcore Metallica Fan be revert They weren t vandalism just closure on some GAs after I vote at New York Dolls FAC And please don t remove the template from the talk page since I m retire now\n"
     ]
    }
   ],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text) \n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "print(\"Исходный текст:\", data.loc[0,'text'])\n",
    "print(\"Лемматизированный текст:\", [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(data.loc[0,'text'])])\n",
    "print(\"Очищенный и лемматизированный текст:\", \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in \n",
    "                                                        nltk.word_tokenize(clear_text(data.loc[0,'text']))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизатор работает корректно. Лемматизируем все текстовые строки датасета.  \n",
    "\n",
    "*CPU times: user 30min 12s, sys: 2min 33s, total: 32min 46s*  \n",
    "*Wall time: 32min 59s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 9s, sys: 2min 38s, total: 33min 48s\n",
      "Wall time: 34min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['lemm_text'] = data['text'].map(lambda x: \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w))\n",
    "                                                         for w in nltk.word_tokenize(clear_text(x))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация успешно проведена. Теперь можно рассчитать **TFIDF** для корпуса лемматизированных текстов для формирования набора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not try to edit war It s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir be my hero Any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  Explanation Why the edits make under my userna...  \n",
       "1  D aww He match this background colour I m seem...  \n",
       "2  Hey man I m really not try to edit war It s ju...  \n",
       "3  More I can t make any real suggestion on impro...  \n",
       "4  You sir be my hero Any chance you remember wha...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим матрицу TF-IDF по корпусу лемматизированных текстов, однако прежде разобьем датасет на выборки обучающую и валидационную в соотношении 75:25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 3) (39893, 3)\n"
     ]
    }
   ],
   "source": [
    "r=42 # random_state\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевой признак и набор признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678,) (39893,) (119678,) (39893,)\n"
     ]
    }
   ],
   "source": [
    "target_train = train['toxic']\n",
    "target_test = test['toxic']\n",
    "features_train = train['lemm_text'].astype('U').values\n",
    "features_test = test['lemm_text'].astype('U').values\n",
    "print(features_train.shape, features_test.shape, target_train.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим счетчик и укажем в нем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "#count_tf_idf = TfidfVectorizer(stop_words=stopwords, ngram_range=(2,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf=TfidfVectorizer(stop_words=stopwords, lowercase=True, min_df=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем TF-IDF для корпуса текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<119678x13943 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2931194 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 13943)\n",
      "CPU times: user 7.41 s, sys: 109 ms, total: 7.52 s\n",
      "Wall time: 7.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_features_train = count_tf_idf.fit_transform(features_train)\n",
    "display(tfidf_features_train)\n",
    "print(tfidf_features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39893, 13943)\n",
      "CPU times: user 2.37 s, sys: 277 µs, total: 2.37 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_features_test = count_tf_idf.transform(features_test)\n",
    "print(tfidf_features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подготовили выборки для проведения обучения разных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Создадим функцию для поиска лучших параметров модели при помощи GrindSearch:\n",
    "def gridsrch_model(model, params):\n",
    "    grid_model = GridSearchCV(model, param_grid=params, scoring='f1', cv=3, verbose=100)  \n",
    "    return grid_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **'Logistic Regression'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = LogisticRegression()\n",
    "grid_params_linear = {'class_weight': ['balanced', None]}\n",
    "\n",
    "grid_model = gridsrch_model(model_linear, grid_params_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CPU times: user 45.2 s, sys: 36.1 s, total: 1min 21s*  \n",
    "*Wall time: 1min 21s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] class_weight=balanced ...........................................\n",
      "[CV] ............... class_weight=balanced, score=0.723, total=  12.3s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.3s remaining:    0.0s\n",
      "[CV] class_weight=balanced ...........................................\n",
      "[CV] ............... class_weight=balanced, score=0.727, total=  14.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   26.6s remaining:    0.0s\n",
      "[CV] class_weight=balanced ...........................................\n",
      "[CV] ............... class_weight=balanced, score=0.728, total=  14.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   40.7s remaining:    0.0s\n",
      "[CV] class_weight=None ...............................................\n",
      "[CV] ................... class_weight=None, score=0.710, total=   8.5s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   49.2s remaining:    0.0s\n",
      "[CV] class_weight=None ...............................................\n",
      "[CV] ................... class_weight=None, score=0.720, total=   9.1s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   58.3s remaining:    0.0s\n",
      "[CV] class_weight=None ...............................................\n",
      "[CV] ................... class_weight=None, score=0.719, total=   8.4s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.1min finished\n",
      "CPU times: user 45.2 s, sys: 36.1 s, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'class_weight': ['balanced', None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Обучим модель\n",
    "grid_model.fit(tfidf_features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель логистической регрессии:\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Лучшее значение F1: 0.7260\n"
     ]
    }
   ],
   "source": [
    "print('Лучшая модель логистической регрессии:')\n",
    "print(grid_model.best_estimator_)\n",
    "print('Лучшее значение F1: {:.4f}'.format(grid_model.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1 тестовой выборки для модели логистической регрессии: 0.7318\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_model.predict(tfidf_features_test)\n",
    "f1_test = f1_score(target_test, predictions)\n",
    "print('Лучшее значение F1 тестовой выборки для модели логистической регрессии: {:.4f}'.format(f1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Зафиксируем значения F1 для тестовой выборки.\n",
    "model_1 = 0.7318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **'Дерево решений'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=r)\n",
    "grid_params_tree = {'max_depth': range(1, 6)}\n",
    "\n",
    "grid_model = gridsrch_model(model_tree, grid_params_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CPU times: user 23.2 s, sys: 33.5 ms, total: 23.3 s*  \n",
    "*Wall time: 23.5 s*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] max_depth=1 .....................................................\n",
      "[CV] ......................... max_depth=1, score=0.349, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[CV] max_depth=1 .....................................................\n",
      "[CV] ......................... max_depth=1, score=0.356, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[CV] max_depth=1 .....................................................\n",
      "[CV] ......................... max_depth=1, score=0.358, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.8s remaining:    0.0s\n",
      "[CV] max_depth=2 .....................................................\n",
      "[CV] ......................... max_depth=2, score=0.410, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.7s remaining:    0.0s\n",
      "[CV] max_depth=2 .....................................................\n",
      "[CV] ......................... max_depth=2, score=0.415, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.6s remaining:    0.0s\n",
      "[CV] max_depth=2 .....................................................\n",
      "[CV] ......................... max_depth=2, score=0.419, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    4.5s remaining:    0.0s\n",
      "[CV] max_depth=3 .....................................................\n",
      "[CV] ......................... max_depth=3, score=0.449, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    5.9s remaining:    0.0s\n",
      "[CV] max_depth=3 .....................................................\n",
      "[CV] ......................... max_depth=3, score=0.457, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.2s remaining:    0.0s\n",
      "[CV] max_depth=3 .....................................................\n",
      "[CV] ......................... max_depth=3, score=0.465, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.5s remaining:    0.0s\n",
      "[CV] max_depth=4 .....................................................\n",
      "[CV] ......................... max_depth=4, score=0.487, total=   1.8s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.2s remaining:    0.0s\n",
      "[CV] max_depth=4 .....................................................\n",
      "[CV] ......................... max_depth=4, score=0.496, total=   1.7s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   11.9s remaining:    0.0s\n",
      "[CV] max_depth=4 .....................................................\n",
      "[CV] ......................... max_depth=4, score=0.500, total=   1.8s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   13.8s remaining:    0.0s\n",
      "[CV] max_depth=5 .....................................................\n",
      "[CV] ......................... max_depth=5, score=0.505, total=   2.1s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   15.9s remaining:    0.0s\n",
      "[CV] max_depth=5 .....................................................\n",
      "[CV] ......................... max_depth=5, score=0.523, total=   2.2s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   18.1s remaining:    0.0s\n",
      "[CV] max_depth=5 .....................................................\n",
      "[CV] ......................... max_depth=5, score=0.515, total=   2.2s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   20.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   20.3s finished\n",
      "CPU times: user 23.2 s, sys: 33.5 ms, total: 23.3 s\n",
      "Wall time: 23.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=42,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None, param_grid={'max_depth': range(1, 6)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Обучим модель\n",
    "grid_model.fit(tfidf_features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель дерева решений:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best')\n",
      "Лучшее значение F1: 0.5146\n"
     ]
    }
   ],
   "source": [
    "print('Лучшая модель дерева решений:')\n",
    "print(grid_model.best_estimator_)\n",
    "print('Лучшее значение F1: {:.4f}'.format(grid_model.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1 тестовой выборки для дерева решений: 0.5402\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_model.predict(tfidf_features_test)\n",
    "f1_test = f1_score(target_test, predictions)\n",
    "print('Лучшее значение F1 тестовой выборки для дерева решений: {:.4f}'.format(f1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Зафиксируем значения F1 для тестовой выборки.\n",
    "model_2 = 0.5402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **'Случайный лес'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CPU times: user 36.7 s, sys: 28.8 ms, total: 36.7 s*  \n",
    "*Wall time: 37.2 s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.7 s, sys: 28.8 ms, total: 36.7 s\n",
      "Wall time: 37.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#model_forest = RandomForestClassifier(random_state=r, n_estimators=50, max_depth=10, class_weight='balanced')\n",
    "#model_forest = RandomForestClassifier(random_state=r, n_estimators=100, max_depth=5, class_weight='balanced')\n",
    "#model_forest = RandomForestClassifier(random_state=r, n_estimators=200, max_depth=5, class_weight='balanced')\n",
    "#model_forest = RandomForestClassifier(random_state=r, n_estimators=200, max_depth=10, class_weight='balanced')\n",
    "#model_forest = RandomForestClassifier(random_state=r, n_estimators=200, max_depth=50, class_weight='balanced')\n",
    "model_forest = RandomForestClassifier(random_state=r, class_weight='balanced')\n",
    "model_forest.fit(tfidf_features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1 тестовой выборки для случайного леса: 0.6505\n"
     ]
    }
   ],
   "source": [
    "predictions = model_forest.predict(tfidf_features_test)\n",
    "f1_test = f1_score(target_test, predictions)\n",
    "print('Лучшее значение F1 тестовой выборки для случайного леса: {:.4f}'.format(f1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Зафиксируем значения F1 для тестовой выборки.\n",
    "model_3 = 0.6505"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **'CatboostClassifier'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CPU times: user 55min 11s, sys: 1min 13s, total: 56min 24s*  \n",
    "*Wall time: 56min 40s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.064894\n",
      "0:\tlearn: 0.6256163\ttotal: 4.21s\tremaining: 1h 10m 9s\n",
      "1:\tlearn: 0.5678953\ttotal: 7.61s\tremaining: 1h 3m 18s\n",
      "2:\tlearn: 0.5175887\ttotal: 11s\tremaining: 1h 59s\n",
      "3:\tlearn: 0.4759956\ttotal: 14.4s\tremaining: 59m 49s\n",
      "4:\tlearn: 0.4409404\ttotal: 17.8s\tremaining: 59m 4s\n",
      "5:\tlearn: 0.4109206\ttotal: 21.2s\tremaining: 58m 34s\n",
      "6:\tlearn: 0.3854108\ttotal: 24.7s\tremaining: 58m 24s\n",
      "7:\tlearn: 0.3643473\ttotal: 28.1s\tremaining: 58m 5s\n",
      "8:\tlearn: 0.3453903\ttotal: 31.5s\tremaining: 57m 49s\n",
      "9:\tlearn: 0.3294656\ttotal: 34.9s\tremaining: 57m 35s\n",
      "10:\tlearn: 0.3158190\ttotal: 38.3s\tremaining: 57m 24s\n",
      "11:\tlearn: 0.3039829\ttotal: 41.8s\tremaining: 57m 22s\n",
      "12:\tlearn: 0.2937493\ttotal: 45.4s\tremaining: 57m 27s\n",
      "13:\tlearn: 0.2848313\ttotal: 48.9s\tremaining: 57m 24s\n",
      "14:\tlearn: 0.2761583\ttotal: 52.6s\tremaining: 57m 34s\n",
      "15:\tlearn: 0.2693633\ttotal: 56.2s\tremaining: 57m 36s\n",
      "16:\tlearn: 0.2638044\ttotal: 59.6s\tremaining: 57m 27s\n",
      "17:\tlearn: 0.2588968\ttotal: 1m 3s\tremaining: 57m 22s\n",
      "18:\tlearn: 0.2545263\ttotal: 1m 6s\tremaining: 57m 13s\n",
      "19:\tlearn: 0.2504990\ttotal: 1m 9s\tremaining: 57m 5s\n",
      "20:\tlearn: 0.2471315\ttotal: 1m 13s\tremaining: 56m 57s\n",
      "21:\tlearn: 0.2434055\ttotal: 1m 17s\tremaining: 57m 2s\n",
      "22:\tlearn: 0.2406551\ttotal: 1m 20s\tremaining: 56m 55s\n",
      "23:\tlearn: 0.2381582\ttotal: 1m 23s\tremaining: 56m 47s\n",
      "24:\tlearn: 0.2357433\ttotal: 1m 27s\tremaining: 56m 40s\n",
      "25:\tlearn: 0.2336963\ttotal: 1m 30s\tremaining: 56m 37s\n",
      "26:\tlearn: 0.2317394\ttotal: 1m 34s\tremaining: 56m 30s\n",
      "27:\tlearn: 0.2294821\ttotal: 1m 37s\tremaining: 56m 31s\n",
      "28:\tlearn: 0.2276104\ttotal: 1m 41s\tremaining: 56m 28s\n",
      "29:\tlearn: 0.2260618\ttotal: 1m 44s\tremaining: 56m 21s\n",
      "30:\tlearn: 0.2246688\ttotal: 1m 48s\tremaining: 56m 18s\n",
      "31:\tlearn: 0.2232084\ttotal: 1m 51s\tremaining: 56m 12s\n",
      "32:\tlearn: 0.2216922\ttotal: 1m 54s\tremaining: 56m 6s\n",
      "33:\tlearn: 0.2204813\ttotal: 1m 58s\tremaining: 56m\n",
      "34:\tlearn: 0.2193564\ttotal: 2m 1s\tremaining: 55m 55s\n",
      "35:\tlearn: 0.2182883\ttotal: 2m 5s\tremaining: 55m 51s\n",
      "36:\tlearn: 0.2172612\ttotal: 2m 8s\tremaining: 55m 46s\n",
      "37:\tlearn: 0.2163667\ttotal: 2m 11s\tremaining: 55m 41s\n",
      "38:\tlearn: 0.2154681\ttotal: 2m 15s\tremaining: 55m 33s\n",
      "39:\tlearn: 0.2146031\ttotal: 2m 18s\tremaining: 55m 25s\n",
      "40:\tlearn: 0.2138107\ttotal: 2m 21s\tremaining: 55m 18s\n",
      "41:\tlearn: 0.2129602\ttotal: 2m 25s\tremaining: 55m 13s\n",
      "42:\tlearn: 0.2122370\ttotal: 2m 28s\tremaining: 55m 8s\n",
      "43:\tlearn: 0.2115395\ttotal: 2m 31s\tremaining: 55m 2s\n",
      "44:\tlearn: 0.2108244\ttotal: 2m 35s\tremaining: 54m 55s\n",
      "45:\tlearn: 0.2101526\ttotal: 2m 38s\tremaining: 54m 50s\n",
      "46:\tlearn: 0.2091117\ttotal: 2m 42s\tremaining: 54m 48s\n",
      "47:\tlearn: 0.2084495\ttotal: 2m 45s\tremaining: 54m 45s\n",
      "48:\tlearn: 0.2076407\ttotal: 2m 49s\tremaining: 54m 43s\n",
      "49:\tlearn: 0.2070052\ttotal: 2m 52s\tremaining: 54m 38s\n",
      "50:\tlearn: 0.2063177\ttotal: 2m 55s\tremaining: 54m 34s\n",
      "51:\tlearn: 0.2056575\ttotal: 2m 59s\tremaining: 54m 29s\n",
      "52:\tlearn: 0.2049591\ttotal: 3m 2s\tremaining: 54m 23s\n",
      "53:\tlearn: 0.2042574\ttotal: 3m 6s\tremaining: 54m 19s\n",
      "54:\tlearn: 0.2037189\ttotal: 3m 9s\tremaining: 54m 13s\n",
      "55:\tlearn: 0.2030423\ttotal: 3m 12s\tremaining: 54m 12s\n",
      "56:\tlearn: 0.2024409\ttotal: 3m 16s\tremaining: 54m 6s\n",
      "57:\tlearn: 0.2019247\ttotal: 3m 19s\tremaining: 54m 2s\n",
      "58:\tlearn: 0.2012082\ttotal: 3m 23s\tremaining: 54m\n",
      "59:\tlearn: 0.2007910\ttotal: 3m 26s\tremaining: 53m 54s\n",
      "60:\tlearn: 0.2002589\ttotal: 3m 29s\tremaining: 53m 50s\n",
      "61:\tlearn: 0.1994114\ttotal: 3m 33s\tremaining: 53m 49s\n",
      "62:\tlearn: 0.1989858\ttotal: 3m 36s\tremaining: 53m 43s\n",
      "63:\tlearn: 0.1985119\ttotal: 3m 40s\tremaining: 53m 39s\n",
      "64:\tlearn: 0.1980407\ttotal: 3m 43s\tremaining: 53m 35s\n",
      "65:\tlearn: 0.1974955\ttotal: 3m 46s\tremaining: 53m 31s\n",
      "66:\tlearn: 0.1968921\ttotal: 3m 50s\tremaining: 53m 30s\n",
      "67:\tlearn: 0.1963447\ttotal: 3m 54s\tremaining: 53m 27s\n",
      "68:\tlearn: 0.1958696\ttotal: 3m 57s\tremaining: 53m 23s\n",
      "69:\tlearn: 0.1954153\ttotal: 4m\tremaining: 53m 19s\n",
      "70:\tlearn: 0.1949774\ttotal: 4m 4s\tremaining: 53m 14s\n",
      "71:\tlearn: 0.1945279\ttotal: 4m 7s\tremaining: 53m 9s\n",
      "72:\tlearn: 0.1940713\ttotal: 4m 10s\tremaining: 53m 5s\n",
      "73:\tlearn: 0.1935758\ttotal: 4m 14s\tremaining: 53m 2s\n",
      "74:\tlearn: 0.1929720\ttotal: 4m 17s\tremaining: 53m\n",
      "75:\tlearn: 0.1926142\ttotal: 4m 21s\tremaining: 52m 55s\n",
      "76:\tlearn: 0.1922078\ttotal: 4m 24s\tremaining: 52m 51s\n",
      "77:\tlearn: 0.1917177\ttotal: 4m 28s\tremaining: 52m 48s\n",
      "78:\tlearn: 0.1913855\ttotal: 4m 31s\tremaining: 52m 44s\n",
      "79:\tlearn: 0.1910399\ttotal: 4m 34s\tremaining: 52m 39s\n",
      "80:\tlearn: 0.1906940\ttotal: 4m 38s\tremaining: 52m 35s\n",
      "81:\tlearn: 0.1902381\ttotal: 4m 41s\tremaining: 52m 30s\n",
      "82:\tlearn: 0.1898840\ttotal: 4m 44s\tremaining: 52m 28s\n",
      "83:\tlearn: 0.1895676\ttotal: 4m 48s\tremaining: 52m 23s\n",
      "84:\tlearn: 0.1892368\ttotal: 4m 51s\tremaining: 52m 19s\n",
      "85:\tlearn: 0.1887365\ttotal: 4m 55s\tremaining: 52m 15s\n",
      "86:\tlearn: 0.1884584\ttotal: 4m 58s\tremaining: 52m 10s\n",
      "87:\tlearn: 0.1879734\ttotal: 5m 1s\tremaining: 52m 7s\n",
      "88:\tlearn: 0.1876821\ttotal: 5m 5s\tremaining: 52m 3s\n",
      "89:\tlearn: 0.1873808\ttotal: 5m 8s\tremaining: 51m 59s\n",
      "90:\tlearn: 0.1871133\ttotal: 5m 11s\tremaining: 51m 55s\n",
      "91:\tlearn: 0.1868437\ttotal: 5m 15s\tremaining: 51m 52s\n",
      "92:\tlearn: 0.1863890\ttotal: 5m 18s\tremaining: 51m 49s\n",
      "93:\tlearn: 0.1859581\ttotal: 5m 22s\tremaining: 51m 45s\n",
      "94:\tlearn: 0.1856674\ttotal: 5m 25s\tremaining: 51m 41s\n",
      "95:\tlearn: 0.1853319\ttotal: 5m 28s\tremaining: 51m 36s\n",
      "96:\tlearn: 0.1850507\ttotal: 5m 32s\tremaining: 51m 31s\n",
      "97:\tlearn: 0.1847819\ttotal: 5m 35s\tremaining: 51m 27s\n",
      "98:\tlearn: 0.1843661\ttotal: 5m 38s\tremaining: 51m 24s\n",
      "99:\tlearn: 0.1840644\ttotal: 5m 42s\tremaining: 51m 20s\n",
      "100:\tlearn: 0.1837928\ttotal: 5m 45s\tremaining: 51m 16s\n",
      "101:\tlearn: 0.1834328\ttotal: 5m 48s\tremaining: 51m 11s\n",
      "102:\tlearn: 0.1830946\ttotal: 5m 52s\tremaining: 51m 8s\n",
      "103:\tlearn: 0.1828321\ttotal: 5m 55s\tremaining: 51m 3s\n",
      "104:\tlearn: 0.1824343\ttotal: 5m 59s\tremaining: 51m\n",
      "105:\tlearn: 0.1821249\ttotal: 6m 2s\tremaining: 50m 56s\n",
      "106:\tlearn: 0.1818496\ttotal: 6m 5s\tremaining: 50m 52s\n",
      "107:\tlearn: 0.1815119\ttotal: 6m 9s\tremaining: 50m 47s\n",
      "108:\tlearn: 0.1812560\ttotal: 6m 12s\tremaining: 50m 44s\n",
      "109:\tlearn: 0.1809691\ttotal: 6m 15s\tremaining: 50m 39s\n",
      "110:\tlearn: 0.1807210\ttotal: 6m 19s\tremaining: 50m 35s\n",
      "111:\tlearn: 0.1804180\ttotal: 6m 22s\tremaining: 50m 32s\n",
      "112:\tlearn: 0.1801297\ttotal: 6m 25s\tremaining: 50m 28s\n",
      "113:\tlearn: 0.1798253\ttotal: 6m 29s\tremaining: 50m 24s\n",
      "114:\tlearn: 0.1795495\ttotal: 6m 32s\tremaining: 50m 20s\n",
      "115:\tlearn: 0.1793222\ttotal: 6m 35s\tremaining: 50m 17s\n",
      "116:\tlearn: 0.1791065\ttotal: 6m 39s\tremaining: 50m 12s\n",
      "117:\tlearn: 0.1787769\ttotal: 6m 42s\tremaining: 50m 8s\n",
      "118:\tlearn: 0.1784032\ttotal: 6m 46s\tremaining: 50m 6s\n",
      "119:\tlearn: 0.1781808\ttotal: 6m 49s\tremaining: 50m 3s\n",
      "120:\tlearn: 0.1779335\ttotal: 6m 52s\tremaining: 49m 58s\n",
      "121:\tlearn: 0.1777301\ttotal: 6m 56s\tremaining: 49m 54s\n",
      "122:\tlearn: 0.1775285\ttotal: 6m 59s\tremaining: 49m 49s\n",
      "123:\tlearn: 0.1773074\ttotal: 7m 2s\tremaining: 49m 45s\n",
      "124:\tlearn: 0.1770953\ttotal: 7m 6s\tremaining: 49m 42s\n",
      "125:\tlearn: 0.1768015\ttotal: 7m 9s\tremaining: 49m 38s\n",
      "126:\tlearn: 0.1765923\ttotal: 7m 12s\tremaining: 49m 34s\n",
      "127:\tlearn: 0.1762985\ttotal: 7m 16s\tremaining: 49m 32s\n",
      "128:\tlearn: 0.1760561\ttotal: 7m 19s\tremaining: 49m 28s\n",
      "129:\tlearn: 0.1757446\ttotal: 7m 23s\tremaining: 49m 25s\n",
      "130:\tlearn: 0.1755604\ttotal: 7m 26s\tremaining: 49m 22s\n",
      "131:\tlearn: 0.1753016\ttotal: 7m 29s\tremaining: 49m 18s\n",
      "132:\tlearn: 0.1750697\ttotal: 7m 33s\tremaining: 49m 15s\n",
      "133:\tlearn: 0.1748410\ttotal: 7m 36s\tremaining: 49m 11s\n",
      "134:\tlearn: 0.1746507\ttotal: 7m 39s\tremaining: 49m 6s\n",
      "135:\tlearn: 0.1744379\ttotal: 7m 43s\tremaining: 49m 2s\n",
      "136:\tlearn: 0.1742483\ttotal: 7m 46s\tremaining: 48m 59s\n",
      "137:\tlearn: 0.1739305\ttotal: 7m 50s\tremaining: 48m 55s\n",
      "138:\tlearn: 0.1737393\ttotal: 7m 53s\tremaining: 48m 52s\n",
      "139:\tlearn: 0.1735173\ttotal: 7m 56s\tremaining: 48m 48s\n",
      "140:\tlearn: 0.1731896\ttotal: 8m\tremaining: 48m 46s\n",
      "141:\tlearn: 0.1730050\ttotal: 8m 3s\tremaining: 48m 42s\n",
      "142:\tlearn: 0.1728034\ttotal: 8m 7s\tremaining: 48m 38s\n",
      "143:\tlearn: 0.1725771\ttotal: 8m 10s\tremaining: 48m 34s\n",
      "144:\tlearn: 0.1724130\ttotal: 8m 13s\tremaining: 48m 31s\n",
      "145:\tlearn: 0.1721451\ttotal: 8m 17s\tremaining: 48m 28s\n",
      "146:\tlearn: 0.1719587\ttotal: 8m 20s\tremaining: 48m 24s\n",
      "147:\tlearn: 0.1717819\ttotal: 8m 23s\tremaining: 48m 20s\n",
      "148:\tlearn: 0.1715695\ttotal: 8m 27s\tremaining: 48m 17s\n",
      "149:\tlearn: 0.1712708\ttotal: 8m 30s\tremaining: 48m 13s\n",
      "150:\tlearn: 0.1711059\ttotal: 8m 34s\tremaining: 48m 10s\n",
      "151:\tlearn: 0.1709257\ttotal: 8m 37s\tremaining: 48m 6s\n",
      "152:\tlearn: 0.1706872\ttotal: 8m 40s\tremaining: 48m 2s\n",
      "153:\tlearn: 0.1705034\ttotal: 8m 44s\tremaining: 47m 58s\n",
      "154:\tlearn: 0.1701926\ttotal: 8m 47s\tremaining: 47m 56s\n",
      "155:\tlearn: 0.1698536\ttotal: 8m 51s\tremaining: 47m 53s\n",
      "156:\tlearn: 0.1696650\ttotal: 8m 54s\tremaining: 47m 49s\n",
      "157:\tlearn: 0.1694605\ttotal: 8m 57s\tremaining: 47m 46s\n",
      "158:\tlearn: 0.1692832\ttotal: 9m 1s\tremaining: 47m 42s\n",
      "159:\tlearn: 0.1691156\ttotal: 9m 4s\tremaining: 47m 38s\n",
      "160:\tlearn: 0.1688297\ttotal: 9m 7s\tremaining: 47m 35s\n",
      "161:\tlearn: 0.1686747\ttotal: 9m 11s\tremaining: 47m 31s\n",
      "162:\tlearn: 0.1684125\ttotal: 9m 14s\tremaining: 47m 28s\n",
      "163:\tlearn: 0.1681847\ttotal: 9m 18s\tremaining: 47m 24s\n",
      "164:\tlearn: 0.1680268\ttotal: 9m 21s\tremaining: 47m 21s\n",
      "165:\tlearn: 0.1678773\ttotal: 9m 24s\tremaining: 47m 17s\n",
      "166:\tlearn: 0.1677231\ttotal: 9m 28s\tremaining: 47m 13s\n",
      "167:\tlearn: 0.1675167\ttotal: 9m 31s\tremaining: 47m 10s\n",
      "168:\tlearn: 0.1673033\ttotal: 9m 34s\tremaining: 47m 7s\n",
      "169:\tlearn: 0.1671448\ttotal: 9m 38s\tremaining: 47m 3s\n",
      "170:\tlearn: 0.1669115\ttotal: 9m 41s\tremaining: 47m\n",
      "171:\tlearn: 0.1667618\ttotal: 9m 45s\tremaining: 46m 56s\n",
      "172:\tlearn: 0.1666006\ttotal: 9m 48s\tremaining: 46m 53s\n",
      "173:\tlearn: 0.1664387\ttotal: 9m 51s\tremaining: 46m 49s\n",
      "174:\tlearn: 0.1662821\ttotal: 9m 55s\tremaining: 46m 45s\n",
      "175:\tlearn: 0.1660905\ttotal: 9m 58s\tremaining: 46m 42s\n",
      "176:\tlearn: 0.1659543\ttotal: 10m 1s\tremaining: 46m 39s\n",
      "177:\tlearn: 0.1657708\ttotal: 10m 5s\tremaining: 46m 35s\n",
      "178:\tlearn: 0.1655816\ttotal: 10m 8s\tremaining: 46m 32s\n",
      "179:\tlearn: 0.1654224\ttotal: 10m 12s\tremaining: 46m 28s\n",
      "180:\tlearn: 0.1652804\ttotal: 10m 15s\tremaining: 46m 25s\n",
      "181:\tlearn: 0.1650797\ttotal: 10m 18s\tremaining: 46m 21s\n",
      "182:\tlearn: 0.1649172\ttotal: 10m 22s\tremaining: 46m 18s\n",
      "183:\tlearn: 0.1647148\ttotal: 10m 25s\tremaining: 46m 15s\n",
      "184:\tlearn: 0.1645963\ttotal: 10m 29s\tremaining: 46m 12s\n",
      "185:\tlearn: 0.1643641\ttotal: 10m 32s\tremaining: 46m 8s\n",
      "186:\tlearn: 0.1642387\ttotal: 10m 35s\tremaining: 46m 4s\n",
      "187:\tlearn: 0.1640831\ttotal: 10m 39s\tremaining: 46m 1s\n",
      "188:\tlearn: 0.1638547\ttotal: 10m 42s\tremaining: 45m 58s\n",
      "189:\tlearn: 0.1637305\ttotal: 10m 46s\tremaining: 45m 55s\n",
      "190:\tlearn: 0.1635506\ttotal: 10m 49s\tremaining: 45m 51s\n",
      "191:\tlearn: 0.1633332\ttotal: 10m 52s\tremaining: 45m 47s\n",
      "192:\tlearn: 0.1631810\ttotal: 10m 56s\tremaining: 45m 44s\n",
      "193:\tlearn: 0.1630465\ttotal: 10m 59s\tremaining: 45m 40s\n",
      "194:\tlearn: 0.1628983\ttotal: 11m 3s\tremaining: 45m 37s\n",
      "195:\tlearn: 0.1627582\ttotal: 11m 6s\tremaining: 45m 33s\n",
      "196:\tlearn: 0.1626317\ttotal: 11m 9s\tremaining: 45m 30s\n",
      "197:\tlearn: 0.1624870\ttotal: 11m 13s\tremaining: 45m 26s\n",
      "198:\tlearn: 0.1623548\ttotal: 11m 16s\tremaining: 45m 22s\n",
      "199:\tlearn: 0.1622157\ttotal: 11m 19s\tremaining: 45m 18s\n",
      "200:\tlearn: 0.1620546\ttotal: 11m 23s\tremaining: 45m 15s\n",
      "201:\tlearn: 0.1619157\ttotal: 11m 26s\tremaining: 45m 11s\n",
      "202:\tlearn: 0.1617839\ttotal: 11m 29s\tremaining: 45m 8s\n",
      "203:\tlearn: 0.1616352\ttotal: 11m 33s\tremaining: 45m 4s\n",
      "204:\tlearn: 0.1614495\ttotal: 11m 36s\tremaining: 45m\n",
      "205:\tlearn: 0.1612148\ttotal: 11m 39s\tremaining: 44m 57s\n",
      "206:\tlearn: 0.1610820\ttotal: 11m 43s\tremaining: 44m 53s\n",
      "207:\tlearn: 0.1609561\ttotal: 11m 46s\tremaining: 44m 50s\n",
      "208:\tlearn: 0.1607511\ttotal: 11m 49s\tremaining: 44m 46s\n",
      "209:\tlearn: 0.1605416\ttotal: 11m 53s\tremaining: 44m 43s\n",
      "210:\tlearn: 0.1602995\ttotal: 11m 56s\tremaining: 44m 40s\n",
      "211:\tlearn: 0.1601460\ttotal: 12m\tremaining: 44m 37s\n",
      "212:\tlearn: 0.1599484\ttotal: 12m 3s\tremaining: 44m 33s\n",
      "213:\tlearn: 0.1598148\ttotal: 12m 6s\tremaining: 44m 30s\n",
      "214:\tlearn: 0.1596578\ttotal: 12m 10s\tremaining: 44m 26s\n",
      "215:\tlearn: 0.1594729\ttotal: 12m 13s\tremaining: 44m 22s\n",
      "216:\tlearn: 0.1592853\ttotal: 12m 17s\tremaining: 44m 19s\n",
      "217:\tlearn: 0.1591090\ttotal: 12m 20s\tremaining: 44m 16s\n",
      "218:\tlearn: 0.1588968\ttotal: 12m 23s\tremaining: 44m 13s\n",
      "219:\tlearn: 0.1587635\ttotal: 12m 27s\tremaining: 44m 9s\n",
      "220:\tlearn: 0.1586101\ttotal: 12m 30s\tremaining: 44m 5s\n",
      "221:\tlearn: 0.1584695\ttotal: 12m 34s\tremaining: 44m 2s\n",
      "222:\tlearn: 0.1583457\ttotal: 12m 37s\tremaining: 43m 59s\n",
      "223:\tlearn: 0.1582260\ttotal: 12m 40s\tremaining: 43m 55s\n",
      "224:\tlearn: 0.1580552\ttotal: 12m 44s\tremaining: 43m 52s\n",
      "225:\tlearn: 0.1579191\ttotal: 12m 47s\tremaining: 43m 48s\n",
      "226:\tlearn: 0.1577984\ttotal: 12m 50s\tremaining: 43m 45s\n",
      "227:\tlearn: 0.1576894\ttotal: 12m 54s\tremaining: 43m 41s\n",
      "228:\tlearn: 0.1575202\ttotal: 12m 57s\tremaining: 43m 38s\n",
      "229:\tlearn: 0.1573374\ttotal: 13m 1s\tremaining: 43m 35s\n",
      "230:\tlearn: 0.1571899\ttotal: 13m 4s\tremaining: 43m 31s\n",
      "231:\tlearn: 0.1570479\ttotal: 13m 7s\tremaining: 43m 28s\n",
      "232:\tlearn: 0.1568749\ttotal: 13m 11s\tremaining: 43m 24s\n",
      "233:\tlearn: 0.1567486\ttotal: 13m 14s\tremaining: 43m 20s\n",
      "234:\tlearn: 0.1565975\ttotal: 13m 17s\tremaining: 43m 17s\n",
      "235:\tlearn: 0.1564776\ttotal: 13m 21s\tremaining: 43m 13s\n",
      "236:\tlearn: 0.1563819\ttotal: 13m 24s\tremaining: 43m 10s\n",
      "237:\tlearn: 0.1561130\ttotal: 13m 27s\tremaining: 43m 6s\n",
      "238:\tlearn: 0.1559804\ttotal: 13m 31s\tremaining: 43m 3s\n",
      "239:\tlearn: 0.1558544\ttotal: 13m 34s\tremaining: 42m 59s\n",
      "240:\tlearn: 0.1557500\ttotal: 13m 38s\tremaining: 42m 56s\n",
      "241:\tlearn: 0.1556327\ttotal: 13m 41s\tremaining: 42m 52s\n",
      "242:\tlearn: 0.1555087\ttotal: 13m 44s\tremaining: 42m 49s\n",
      "243:\tlearn: 0.1553526\ttotal: 13m 48s\tremaining: 42m 45s\n",
      "244:\tlearn: 0.1551999\ttotal: 13m 51s\tremaining: 42m 42s\n",
      "245:\tlearn: 0.1550453\ttotal: 13m 54s\tremaining: 42m 39s\n",
      "246:\tlearn: 0.1549129\ttotal: 13m 58s\tremaining: 42m 35s\n",
      "247:\tlearn: 0.1547649\ttotal: 14m 1s\tremaining: 42m 32s\n",
      "248:\tlearn: 0.1546487\ttotal: 14m 5s\tremaining: 42m 28s\n",
      "249:\tlearn: 0.1545533\ttotal: 14m 8s\tremaining: 42m 24s\n",
      "250:\tlearn: 0.1544334\ttotal: 14m 11s\tremaining: 42m 21s\n",
      "251:\tlearn: 0.1543154\ttotal: 14m 15s\tremaining: 42m 17s\n",
      "252:\tlearn: 0.1541693\ttotal: 14m 18s\tremaining: 42m 14s\n",
      "253:\tlearn: 0.1540611\ttotal: 14m 21s\tremaining: 42m 10s\n",
      "254:\tlearn: 0.1538917\ttotal: 14m 25s\tremaining: 42m 7s\n",
      "255:\tlearn: 0.1537595\ttotal: 14m 28s\tremaining: 42m 4s\n",
      "256:\tlearn: 0.1536199\ttotal: 14m 31s\tremaining: 42m\n",
      "257:\tlearn: 0.1534270\ttotal: 14m 35s\tremaining: 41m 57s\n",
      "258:\tlearn: 0.1533209\ttotal: 14m 38s\tremaining: 41m 53s\n",
      "259:\tlearn: 0.1532171\ttotal: 14m 41s\tremaining: 41m 50s\n",
      "260:\tlearn: 0.1530859\ttotal: 14m 45s\tremaining: 41m 46s\n",
      "261:\tlearn: 0.1529706\ttotal: 14m 48s\tremaining: 41m 43s\n",
      "262:\tlearn: 0.1528164\ttotal: 14m 52s\tremaining: 41m 40s\n",
      "263:\tlearn: 0.1527232\ttotal: 14m 55s\tremaining: 41m 36s\n",
      "264:\tlearn: 0.1526098\ttotal: 14m 59s\tremaining: 41m 33s\n",
      "265:\tlearn: 0.1524763\ttotal: 15m 2s\tremaining: 41m 30s\n",
      "266:\tlearn: 0.1523612\ttotal: 15m 5s\tremaining: 41m 26s\n",
      "267:\tlearn: 0.1522615\ttotal: 15m 9s\tremaining: 41m 23s\n",
      "268:\tlearn: 0.1521686\ttotal: 15m 12s\tremaining: 41m 19s\n",
      "269:\tlearn: 0.1520584\ttotal: 15m 15s\tremaining: 41m 16s\n",
      "270:\tlearn: 0.1519407\ttotal: 15m 19s\tremaining: 41m 12s\n",
      "271:\tlearn: 0.1518522\ttotal: 15m 22s\tremaining: 41m 9s\n",
      "272:\tlearn: 0.1517350\ttotal: 15m 26s\tremaining: 41m 5s\n",
      "273:\tlearn: 0.1515884\ttotal: 15m 29s\tremaining: 41m 2s\n",
      "274:\tlearn: 0.1514714\ttotal: 15m 32s\tremaining: 40m 59s\n",
      "275:\tlearn: 0.1513696\ttotal: 15m 36s\tremaining: 40m 55s\n",
      "276:\tlearn: 0.1512568\ttotal: 15m 39s\tremaining: 40m 52s\n",
      "277:\tlearn: 0.1511227\ttotal: 15m 43s\tremaining: 40m 49s\n",
      "278:\tlearn: 0.1509365\ttotal: 15m 46s\tremaining: 40m 46s\n",
      "279:\tlearn: 0.1508530\ttotal: 15m 49s\tremaining: 40m 42s\n",
      "280:\tlearn: 0.1507738\ttotal: 15m 53s\tremaining: 40m 39s\n",
      "281:\tlearn: 0.1506764\ttotal: 15m 56s\tremaining: 40m 36s\n",
      "282:\tlearn: 0.1505658\ttotal: 16m\tremaining: 40m 32s\n",
      "283:\tlearn: 0.1504639\ttotal: 16m 3s\tremaining: 40m 28s\n",
      "284:\tlearn: 0.1503745\ttotal: 16m 6s\tremaining: 40m 25s\n",
      "285:\tlearn: 0.1502529\ttotal: 16m 10s\tremaining: 40m 22s\n",
      "286:\tlearn: 0.1501756\ttotal: 16m 13s\tremaining: 40m 18s\n",
      "287:\tlearn: 0.1500380\ttotal: 16m 17s\tremaining: 40m 15s\n",
      "288:\tlearn: 0.1498520\ttotal: 16m 20s\tremaining: 40m 12s\n",
      "289:\tlearn: 0.1497736\ttotal: 16m 23s\tremaining: 40m 8s\n",
      "290:\tlearn: 0.1496679\ttotal: 16m 27s\tremaining: 40m 5s\n",
      "291:\tlearn: 0.1495732\ttotal: 16m 30s\tremaining: 40m 1s\n",
      "292:\tlearn: 0.1494480\ttotal: 16m 34s\tremaining: 39m 58s\n",
      "293:\tlearn: 0.1493614\ttotal: 16m 37s\tremaining: 39m 54s\n",
      "294:\tlearn: 0.1492531\ttotal: 16m 40s\tremaining: 39m 51s\n",
      "295:\tlearn: 0.1491613\ttotal: 16m 44s\tremaining: 39m 48s\n",
      "296:\tlearn: 0.1490555\ttotal: 16m 47s\tremaining: 39m 45s\n",
      "297:\tlearn: 0.1489814\ttotal: 16m 50s\tremaining: 39m 41s\n",
      "298:\tlearn: 0.1489022\ttotal: 16m 54s\tremaining: 39m 37s\n",
      "299:\tlearn: 0.1487498\ttotal: 16m 57s\tremaining: 39m 34s\n",
      "300:\tlearn: 0.1486757\ttotal: 17m\tremaining: 39m 30s\n",
      "301:\tlearn: 0.1485784\ttotal: 17m 4s\tremaining: 39m 27s\n",
      "302:\tlearn: 0.1484596\ttotal: 17m 7s\tremaining: 39m 23s\n",
      "303:\tlearn: 0.1483431\ttotal: 17m 10s\tremaining: 39m 20s\n",
      "304:\tlearn: 0.1482626\ttotal: 17m 14s\tremaining: 39m 16s\n",
      "305:\tlearn: 0.1481565\ttotal: 17m 17s\tremaining: 39m 13s\n",
      "306:\tlearn: 0.1480762\ttotal: 17m 20s\tremaining: 39m 9s\n",
      "307:\tlearn: 0.1478999\ttotal: 17m 24s\tremaining: 39m 6s\n",
      "308:\tlearn: 0.1478157\ttotal: 17m 27s\tremaining: 39m 2s\n",
      "309:\tlearn: 0.1476577\ttotal: 17m 31s\tremaining: 38m 59s\n",
      "310:\tlearn: 0.1475376\ttotal: 17m 34s\tremaining: 38m 55s\n",
      "311:\tlearn: 0.1474700\ttotal: 17m 37s\tremaining: 38m 52s\n",
      "312:\tlearn: 0.1473979\ttotal: 17m 41s\tremaining: 38m 49s\n",
      "313:\tlearn: 0.1473057\ttotal: 17m 44s\tremaining: 38m 45s\n",
      "314:\tlearn: 0.1471984\ttotal: 17m 47s\tremaining: 38m 42s\n",
      "315:\tlearn: 0.1471039\ttotal: 17m 51s\tremaining: 38m 38s\n",
      "316:\tlearn: 0.1469531\ttotal: 17m 54s\tremaining: 38m 35s\n",
      "317:\tlearn: 0.1467869\ttotal: 17m 58s\tremaining: 38m 31s\n",
      "318:\tlearn: 0.1466890\ttotal: 18m 1s\tremaining: 38m 28s\n",
      "319:\tlearn: 0.1465284\ttotal: 18m 4s\tremaining: 38m 25s\n",
      "320:\tlearn: 0.1464581\ttotal: 18m 8s\tremaining: 38m 21s\n",
      "321:\tlearn: 0.1463631\ttotal: 18m 11s\tremaining: 38m 18s\n",
      "322:\tlearn: 0.1462761\ttotal: 18m 14s\tremaining: 38m 14s\n",
      "323:\tlearn: 0.1461731\ttotal: 18m 18s\tremaining: 38m 11s\n",
      "324:\tlearn: 0.1460666\ttotal: 18m 21s\tremaining: 38m 7s\n",
      "325:\tlearn: 0.1459829\ttotal: 18m 24s\tremaining: 38m 4s\n",
      "326:\tlearn: 0.1459045\ttotal: 18m 28s\tremaining: 38m\n",
      "327:\tlearn: 0.1458155\ttotal: 18m 31s\tremaining: 37m 57s\n",
      "328:\tlearn: 0.1456826\ttotal: 18m 34s\tremaining: 37m 53s\n",
      "329:\tlearn: 0.1456105\ttotal: 18m 38s\tremaining: 37m 50s\n",
      "330:\tlearn: 0.1455029\ttotal: 18m 41s\tremaining: 37m 46s\n",
      "331:\tlearn: 0.1454275\ttotal: 18m 44s\tremaining: 37m 43s\n",
      "332:\tlearn: 0.1453691\ttotal: 18m 48s\tremaining: 37m 40s\n",
      "333:\tlearn: 0.1452849\ttotal: 18m 51s\tremaining: 37m 36s\n",
      "334:\tlearn: 0.1452106\ttotal: 18m 55s\tremaining: 37m 33s\n",
      "335:\tlearn: 0.1450808\ttotal: 18m 58s\tremaining: 37m 30s\n",
      "336:\tlearn: 0.1449671\ttotal: 19m 1s\tremaining: 37m 26s\n",
      "337:\tlearn: 0.1448430\ttotal: 19m 5s\tremaining: 37m 23s\n",
      "338:\tlearn: 0.1447434\ttotal: 19m 8s\tremaining: 37m 20s\n",
      "339:\tlearn: 0.1446792\ttotal: 19m 12s\tremaining: 37m 16s\n",
      "340:\tlearn: 0.1445805\ttotal: 19m 15s\tremaining: 37m 13s\n",
      "341:\tlearn: 0.1444902\ttotal: 19m 19s\tremaining: 37m 10s\n",
      "342:\tlearn: 0.1444286\ttotal: 19m 22s\tremaining: 37m 6s\n",
      "343:\tlearn: 0.1443030\ttotal: 19m 26s\tremaining: 37m 3s\n",
      "344:\tlearn: 0.1442145\ttotal: 19m 29s\tremaining: 37m\n",
      "345:\tlearn: 0.1441098\ttotal: 19m 32s\tremaining: 36m 56s\n",
      "346:\tlearn: 0.1440354\ttotal: 19m 36s\tremaining: 36m 53s\n",
      "347:\tlearn: 0.1439574\ttotal: 19m 39s\tremaining: 36m 50s\n",
      "348:\tlearn: 0.1438811\ttotal: 19m 42s\tremaining: 36m 46s\n",
      "349:\tlearn: 0.1437266\ttotal: 19m 46s\tremaining: 36m 43s\n",
      "350:\tlearn: 0.1436407\ttotal: 19m 49s\tremaining: 36m 39s\n",
      "351:\tlearn: 0.1435524\ttotal: 19m 53s\tremaining: 36m 36s\n",
      "352:\tlearn: 0.1434847\ttotal: 19m 56s\tremaining: 36m 32s\n",
      "353:\tlearn: 0.1433538\ttotal: 19m 59s\tremaining: 36m 29s\n",
      "354:\tlearn: 0.1432923\ttotal: 20m 2s\tremaining: 36m 25s\n",
      "355:\tlearn: 0.1432172\ttotal: 20m 6s\tremaining: 36m 22s\n",
      "356:\tlearn: 0.1431273\ttotal: 20m 9s\tremaining: 36m 18s\n",
      "357:\tlearn: 0.1430302\ttotal: 20m 13s\tremaining: 36m 15s\n",
      "358:\tlearn: 0.1429536\ttotal: 20m 16s\tremaining: 36m 11s\n",
      "359:\tlearn: 0.1429002\ttotal: 20m 19s\tremaining: 36m 8s\n",
      "360:\tlearn: 0.1428105\ttotal: 20m 23s\tremaining: 36m 4s\n",
      "361:\tlearn: 0.1427416\ttotal: 20m 26s\tremaining: 36m 1s\n",
      "362:\tlearn: 0.1426733\ttotal: 20m 29s\tremaining: 35m 58s\n",
      "363:\tlearn: 0.1426118\ttotal: 20m 33s\tremaining: 35m 54s\n",
      "364:\tlearn: 0.1425361\ttotal: 20m 36s\tremaining: 35m 50s\n",
      "365:\tlearn: 0.1424634\ttotal: 20m 39s\tremaining: 35m 47s\n",
      "366:\tlearn: 0.1423859\ttotal: 20m 43s\tremaining: 35m 44s\n",
      "367:\tlearn: 0.1422575\ttotal: 20m 46s\tremaining: 35m 41s\n",
      "368:\tlearn: 0.1421931\ttotal: 20m 50s\tremaining: 35m 37s\n",
      "369:\tlearn: 0.1420785\ttotal: 20m 53s\tremaining: 35m 34s\n",
      "370:\tlearn: 0.1419995\ttotal: 20m 56s\tremaining: 35m 31s\n",
      "371:\tlearn: 0.1419360\ttotal: 21m\tremaining: 35m 27s\n",
      "372:\tlearn: 0.1418541\ttotal: 21m 3s\tremaining: 35m 24s\n",
      "373:\tlearn: 0.1418044\ttotal: 21m 6s\tremaining: 35m 20s\n",
      "374:\tlearn: 0.1417128\ttotal: 21m 10s\tremaining: 35m 17s\n",
      "375:\tlearn: 0.1416328\ttotal: 21m 13s\tremaining: 35m 14s\n",
      "376:\tlearn: 0.1415778\ttotal: 21m 17s\tremaining: 35m 10s\n",
      "377:\tlearn: 0.1414756\ttotal: 21m 20s\tremaining: 35m 7s\n",
      "378:\tlearn: 0.1413429\ttotal: 21m 23s\tremaining: 35m 3s\n",
      "379:\tlearn: 0.1412147\ttotal: 21m 27s\tremaining: 35m\n",
      "380:\tlearn: 0.1411625\ttotal: 21m 30s\tremaining: 34m 57s\n",
      "381:\tlearn: 0.1410740\ttotal: 21m 34s\tremaining: 34m 53s\n",
      "382:\tlearn: 0.1409747\ttotal: 21m 37s\tremaining: 34m 49s\n",
      "383:\tlearn: 0.1409035\ttotal: 21m 40s\tremaining: 34m 46s\n",
      "384:\tlearn: 0.1408182\ttotal: 21m 44s\tremaining: 34m 43s\n",
      "385:\tlearn: 0.1407482\ttotal: 21m 47s\tremaining: 34m 39s\n",
      "386:\tlearn: 0.1406806\ttotal: 21m 50s\tremaining: 34m 36s\n",
      "387:\tlearn: 0.1405794\ttotal: 21m 54s\tremaining: 34m 32s\n",
      "388:\tlearn: 0.1405221\ttotal: 21m 57s\tremaining: 34m 28s\n",
      "389:\tlearn: 0.1404511\ttotal: 22m\tremaining: 34m 25s\n",
      "390:\tlearn: 0.1403686\ttotal: 22m 3s\tremaining: 34m 21s\n",
      "391:\tlearn: 0.1402886\ttotal: 22m 7s\tremaining: 34m 18s\n",
      "392:\tlearn: 0.1401854\ttotal: 22m 10s\tremaining: 34m 15s\n",
      "393:\tlearn: 0.1401220\ttotal: 22m 14s\tremaining: 34m 11s\n",
      "394:\tlearn: 0.1400365\ttotal: 22m 17s\tremaining: 34m 8s\n",
      "395:\tlearn: 0.1399698\ttotal: 22m 20s\tremaining: 34m 4s\n",
      "396:\tlearn: 0.1398686\ttotal: 22m 24s\tremaining: 34m 1s\n",
      "397:\tlearn: 0.1398216\ttotal: 22m 27s\tremaining: 33m 58s\n",
      "398:\tlearn: 0.1397323\ttotal: 22m 30s\tremaining: 33m 54s\n",
      "399:\tlearn: 0.1396782\ttotal: 22m 34s\tremaining: 33m 51s\n",
      "400:\tlearn: 0.1396107\ttotal: 22m 37s\tremaining: 33m 47s\n",
      "401:\tlearn: 0.1395246\ttotal: 22m 40s\tremaining: 33m 44s\n",
      "402:\tlearn: 0.1394496\ttotal: 22m 44s\tremaining: 33m 40s\n",
      "403:\tlearn: 0.1393890\ttotal: 22m 47s\tremaining: 33m 37s\n",
      "404:\tlearn: 0.1392935\ttotal: 22m 51s\tremaining: 33m 34s\n",
      "405:\tlearn: 0.1392466\ttotal: 22m 54s\tremaining: 33m 30s\n",
      "406:\tlearn: 0.1391763\ttotal: 22m 57s\tremaining: 33m 27s\n",
      "407:\tlearn: 0.1391093\ttotal: 23m 1s\tremaining: 33m 23s\n",
      "408:\tlearn: 0.1390201\ttotal: 23m 4s\tremaining: 33m 20s\n",
      "409:\tlearn: 0.1389366\ttotal: 23m 7s\tremaining: 33m 17s\n",
      "410:\tlearn: 0.1388692\ttotal: 23m 11s\tremaining: 33m 13s\n",
      "411:\tlearn: 0.1388102\ttotal: 23m 14s\tremaining: 33m 10s\n",
      "412:\tlearn: 0.1386869\ttotal: 23m 17s\tremaining: 33m 6s\n",
      "413:\tlearn: 0.1386390\ttotal: 23m 21s\tremaining: 33m 3s\n",
      "414:\tlearn: 0.1385820\ttotal: 23m 24s\tremaining: 32m 59s\n",
      "415:\tlearn: 0.1384860\ttotal: 23m 27s\tremaining: 32m 56s\n",
      "416:\tlearn: 0.1383444\ttotal: 23m 31s\tremaining: 32m 53s\n",
      "417:\tlearn: 0.1382782\ttotal: 23m 34s\tremaining: 32m 50s\n",
      "418:\tlearn: 0.1382249\ttotal: 23m 38s\tremaining: 32m 46s\n",
      "419:\tlearn: 0.1381873\ttotal: 23m 41s\tremaining: 32m 43s\n",
      "420:\tlearn: 0.1381283\ttotal: 23m 44s\tremaining: 32m 39s\n",
      "421:\tlearn: 0.1380347\ttotal: 23m 48s\tremaining: 32m 36s\n",
      "422:\tlearn: 0.1379610\ttotal: 23m 51s\tremaining: 32m 32s\n",
      "423:\tlearn: 0.1378943\ttotal: 23m 55s\tremaining: 32m 29s\n",
      "424:\tlearn: 0.1378032\ttotal: 23m 58s\tremaining: 32m 26s\n",
      "425:\tlearn: 0.1377119\ttotal: 24m 1s\tremaining: 32m 22s\n",
      "426:\tlearn: 0.1376705\ttotal: 24m 5s\tremaining: 32m 19s\n",
      "427:\tlearn: 0.1376129\ttotal: 24m 8s\tremaining: 32m 15s\n",
      "428:\tlearn: 0.1375323\ttotal: 24m 11s\tremaining: 32m 12s\n",
      "429:\tlearn: 0.1374968\ttotal: 24m 14s\tremaining: 32m 8s\n",
      "430:\tlearn: 0.1374057\ttotal: 24m 18s\tremaining: 32m 5s\n",
      "431:\tlearn: 0.1373577\ttotal: 24m 21s\tremaining: 32m 1s\n",
      "432:\tlearn: 0.1372816\ttotal: 24m 24s\tremaining: 31m 58s\n",
      "433:\tlearn: 0.1372371\ttotal: 24m 28s\tremaining: 31m 54s\n",
      "434:\tlearn: 0.1371518\ttotal: 24m 31s\tremaining: 31m 51s\n",
      "435:\tlearn: 0.1370623\ttotal: 24m 34s\tremaining: 31m 48s\n",
      "436:\tlearn: 0.1369796\ttotal: 24m 38s\tremaining: 31m 44s\n",
      "437:\tlearn: 0.1368807\ttotal: 24m 41s\tremaining: 31m 41s\n",
      "438:\tlearn: 0.1368170\ttotal: 24m 45s\tremaining: 31m 38s\n",
      "439:\tlearn: 0.1367240\ttotal: 24m 48s\tremaining: 31m 34s\n",
      "440:\tlearn: 0.1366521\ttotal: 24m 51s\tremaining: 31m 31s\n",
      "441:\tlearn: 0.1366176\ttotal: 24m 55s\tremaining: 31m 27s\n",
      "442:\tlearn: 0.1365491\ttotal: 24m 58s\tremaining: 31m 24s\n",
      "443:\tlearn: 0.1364542\ttotal: 25m 2s\tremaining: 31m 21s\n",
      "444:\tlearn: 0.1363943\ttotal: 25m 5s\tremaining: 31m 17s\n",
      "445:\tlearn: 0.1363392\ttotal: 25m 8s\tremaining: 31m 14s\n",
      "446:\tlearn: 0.1362877\ttotal: 25m 12s\tremaining: 31m 10s\n",
      "447:\tlearn: 0.1362000\ttotal: 25m 15s\tremaining: 31m 7s\n",
      "448:\tlearn: 0.1361627\ttotal: 25m 18s\tremaining: 31m 3s\n",
      "449:\tlearn: 0.1360855\ttotal: 25m 22s\tremaining: 31m\n",
      "450:\tlearn: 0.1360440\ttotal: 25m 25s\tremaining: 30m 57s\n",
      "451:\tlearn: 0.1359858\ttotal: 25m 28s\tremaining: 30m 53s\n",
      "452:\tlearn: 0.1359109\ttotal: 25m 32s\tremaining: 30m 50s\n",
      "453:\tlearn: 0.1358692\ttotal: 25m 35s\tremaining: 30m 46s\n",
      "454:\tlearn: 0.1358193\ttotal: 25m 38s\tremaining: 30m 43s\n",
      "455:\tlearn: 0.1356955\ttotal: 25m 42s\tremaining: 30m 39s\n",
      "456:\tlearn: 0.1356221\ttotal: 25m 45s\tremaining: 30m 36s\n",
      "457:\tlearn: 0.1355504\ttotal: 25m 48s\tremaining: 30m 33s\n",
      "458:\tlearn: 0.1355185\ttotal: 25m 52s\tremaining: 30m 29s\n",
      "459:\tlearn: 0.1354124\ttotal: 25m 55s\tremaining: 30m 26s\n",
      "460:\tlearn: 0.1353453\ttotal: 25m 59s\tremaining: 30m 22s\n",
      "461:\tlearn: 0.1352547\ttotal: 26m 2s\tremaining: 30m 19s\n",
      "462:\tlearn: 0.1351186\ttotal: 26m 5s\tremaining: 30m 16s\n",
      "463:\tlearn: 0.1350130\ttotal: 26m 9s\tremaining: 30m 12s\n",
      "464:\tlearn: 0.1349632\ttotal: 26m 12s\tremaining: 30m 9s\n",
      "465:\tlearn: 0.1349160\ttotal: 26m 16s\tremaining: 30m 6s\n",
      "466:\tlearn: 0.1348817\ttotal: 26m 19s\tremaining: 30m 2s\n",
      "467:\tlearn: 0.1347873\ttotal: 26m 22s\tremaining: 29m 59s\n",
      "468:\tlearn: 0.1347567\ttotal: 26m 25s\tremaining: 29m 55s\n",
      "469:\tlearn: 0.1346948\ttotal: 26m 29s\tremaining: 29m 52s\n",
      "470:\tlearn: 0.1346324\ttotal: 26m 32s\tremaining: 29m 48s\n",
      "471:\tlearn: 0.1345183\ttotal: 26m 36s\tremaining: 29m 45s\n",
      "472:\tlearn: 0.1344512\ttotal: 26m 39s\tremaining: 29m 42s\n",
      "473:\tlearn: 0.1344032\ttotal: 26m 42s\tremaining: 29m 38s\n",
      "474:\tlearn: 0.1343421\ttotal: 26m 46s\tremaining: 29m 35s\n",
      "475:\tlearn: 0.1342507\ttotal: 26m 49s\tremaining: 29m 31s\n",
      "476:\tlearn: 0.1341964\ttotal: 26m 52s\tremaining: 29m 28s\n",
      "477:\tlearn: 0.1341365\ttotal: 26m 56s\tremaining: 29m 25s\n",
      "478:\tlearn: 0.1340375\ttotal: 26m 59s\tremaining: 29m 21s\n",
      "479:\tlearn: 0.1339774\ttotal: 27m 3s\tremaining: 29m 18s\n",
      "480:\tlearn: 0.1339085\ttotal: 27m 6s\tremaining: 29m 15s\n",
      "481:\tlearn: 0.1338546\ttotal: 27m 9s\tremaining: 29m 11s\n",
      "482:\tlearn: 0.1337821\ttotal: 27m 13s\tremaining: 29m 8s\n",
      "483:\tlearn: 0.1337135\ttotal: 27m 16s\tremaining: 29m 4s\n",
      "484:\tlearn: 0.1336785\ttotal: 27m 20s\tremaining: 29m 1s\n",
      "485:\tlearn: 0.1335905\ttotal: 27m 23s\tremaining: 28m 58s\n",
      "486:\tlearn: 0.1335314\ttotal: 27m 26s\tremaining: 28m 54s\n",
      "487:\tlearn: 0.1334604\ttotal: 27m 30s\tremaining: 28m 51s\n",
      "488:\tlearn: 0.1334036\ttotal: 27m 33s\tremaining: 28m 47s\n",
      "489:\tlearn: 0.1333069\ttotal: 27m 36s\tremaining: 28m 44s\n",
      "490:\tlearn: 0.1332428\ttotal: 27m 40s\tremaining: 28m 41s\n",
      "491:\tlearn: 0.1331950\ttotal: 27m 43s\tremaining: 28m 37s\n",
      "492:\tlearn: 0.1331305\ttotal: 27m 47s\tremaining: 28m 34s\n",
      "493:\tlearn: 0.1331014\ttotal: 27m 50s\tremaining: 28m 30s\n",
      "494:\tlearn: 0.1330364\ttotal: 27m 53s\tremaining: 28m 27s\n",
      "495:\tlearn: 0.1330027\ttotal: 27m 56s\tremaining: 28m 23s\n",
      "496:\tlearn: 0.1329268\ttotal: 28m\tremaining: 28m 20s\n",
      "497:\tlearn: 0.1328776\ttotal: 28m 3s\tremaining: 28m 17s\n",
      "498:\tlearn: 0.1327923\ttotal: 28m 7s\tremaining: 28m 13s\n",
      "499:\tlearn: 0.1327280\ttotal: 28m 10s\tremaining: 28m 10s\n",
      "500:\tlearn: 0.1326865\ttotal: 28m 13s\tremaining: 28m 6s\n",
      "501:\tlearn: 0.1326178\ttotal: 28m 16s\tremaining: 28m 3s\n",
      "502:\tlearn: 0.1325611\ttotal: 28m 20s\tremaining: 28m\n",
      "503:\tlearn: 0.1325016\ttotal: 28m 23s\tremaining: 27m 56s\n",
      "504:\tlearn: 0.1324244\ttotal: 28m 27s\tremaining: 27m 53s\n",
      "505:\tlearn: 0.1323935\ttotal: 28m 30s\tremaining: 27m 49s\n",
      "506:\tlearn: 0.1323236\ttotal: 28m 33s\tremaining: 27m 46s\n",
      "507:\tlearn: 0.1322533\ttotal: 28m 37s\tremaining: 27m 43s\n",
      "508:\tlearn: 0.1321927\ttotal: 28m 40s\tremaining: 27m 39s\n",
      "509:\tlearn: 0.1321559\ttotal: 28m 43s\tremaining: 27m 36s\n",
      "510:\tlearn: 0.1320382\ttotal: 28m 47s\tremaining: 27m 33s\n",
      "511:\tlearn: 0.1319759\ttotal: 28m 50s\tremaining: 27m 29s\n",
      "512:\tlearn: 0.1319085\ttotal: 28m 54s\tremaining: 27m 26s\n",
      "513:\tlearn: 0.1317677\ttotal: 28m 57s\tremaining: 27m 22s\n",
      "514:\tlearn: 0.1317305\ttotal: 29m\tremaining: 27m 19s\n",
      "515:\tlearn: 0.1316828\ttotal: 29m 4s\tremaining: 27m 16s\n",
      "516:\tlearn: 0.1316205\ttotal: 29m 7s\tremaining: 27m 12s\n",
      "517:\tlearn: 0.1315822\ttotal: 29m 10s\tremaining: 27m 9s\n",
      "518:\tlearn: 0.1315355\ttotal: 29m 14s\tremaining: 27m 5s\n",
      "519:\tlearn: 0.1314723\ttotal: 29m 17s\tremaining: 27m 2s\n",
      "520:\tlearn: 0.1314279\ttotal: 29m 20s\tremaining: 26m 58s\n",
      "521:\tlearn: 0.1313827\ttotal: 29m 24s\tremaining: 26m 55s\n",
      "522:\tlearn: 0.1313201\ttotal: 29m 27s\tremaining: 26m 52s\n",
      "523:\tlearn: 0.1312704\ttotal: 29m 30s\tremaining: 26m 48s\n",
      "524:\tlearn: 0.1311760\ttotal: 29m 34s\tremaining: 26m 45s\n",
      "525:\tlearn: 0.1311424\ttotal: 29m 37s\tremaining: 26m 41s\n",
      "526:\tlearn: 0.1310911\ttotal: 29m 40s\tremaining: 26m 38s\n",
      "527:\tlearn: 0.1310415\ttotal: 29m 44s\tremaining: 26m 35s\n",
      "528:\tlearn: 0.1309726\ttotal: 29m 47s\tremaining: 26m 31s\n",
      "529:\tlearn: 0.1309144\ttotal: 29m 51s\tremaining: 26m 28s\n",
      "530:\tlearn: 0.1308776\ttotal: 29m 54s\tremaining: 26m 24s\n",
      "531:\tlearn: 0.1308111\ttotal: 29m 57s\tremaining: 26m 21s\n",
      "532:\tlearn: 0.1307002\ttotal: 30m 1s\tremaining: 26m 18s\n",
      "533:\tlearn: 0.1306559\ttotal: 30m 4s\tremaining: 26m 14s\n",
      "534:\tlearn: 0.1306189\ttotal: 30m 7s\tremaining: 26m 11s\n",
      "535:\tlearn: 0.1305696\ttotal: 30m 11s\tremaining: 26m 7s\n",
      "536:\tlearn: 0.1305118\ttotal: 30m 14s\tremaining: 26m 4s\n",
      "537:\tlearn: 0.1304628\ttotal: 30m 17s\tremaining: 26m 1s\n",
      "538:\tlearn: 0.1303515\ttotal: 30m 21s\tremaining: 25m 57s\n",
      "539:\tlearn: 0.1303138\ttotal: 30m 24s\tremaining: 25m 54s\n",
      "540:\tlearn: 0.1302450\ttotal: 30m 28s\tremaining: 25m 50s\n",
      "541:\tlearn: 0.1301531\ttotal: 30m 31s\tremaining: 25m 47s\n",
      "542:\tlearn: 0.1300915\ttotal: 30m 34s\tremaining: 25m 44s\n",
      "543:\tlearn: 0.1300617\ttotal: 30m 38s\tremaining: 25m 40s\n",
      "544:\tlearn: 0.1300114\ttotal: 30m 41s\tremaining: 25m 37s\n",
      "545:\tlearn: 0.1299624\ttotal: 30m 44s\tremaining: 25m 34s\n",
      "546:\tlearn: 0.1299110\ttotal: 30m 48s\tremaining: 25m 30s\n",
      "547:\tlearn: 0.1298565\ttotal: 30m 51s\tremaining: 25m 27s\n",
      "548:\tlearn: 0.1297916\ttotal: 30m 55s\tremaining: 25m 23s\n",
      "549:\tlearn: 0.1297593\ttotal: 30m 58s\tremaining: 25m 20s\n",
      "550:\tlearn: 0.1297044\ttotal: 31m 1s\tremaining: 25m 17s\n",
      "551:\tlearn: 0.1296440\ttotal: 31m 5s\tremaining: 25m 13s\n",
      "552:\tlearn: 0.1296173\ttotal: 31m 8s\tremaining: 25m 10s\n",
      "553:\tlearn: 0.1295417\ttotal: 31m 11s\tremaining: 25m 6s\n",
      "554:\tlearn: 0.1294573\ttotal: 31m 15s\tremaining: 25m 3s\n",
      "555:\tlearn: 0.1294275\ttotal: 31m 18s\tremaining: 25m\n",
      "556:\tlearn: 0.1293481\ttotal: 31m 21s\tremaining: 24m 56s\n",
      "557:\tlearn: 0.1292907\ttotal: 31m 25s\tremaining: 24m 53s\n",
      "558:\tlearn: 0.1292223\ttotal: 31m 28s\tremaining: 24m 49s\n",
      "559:\tlearn: 0.1291618\ttotal: 31m 31s\tremaining: 24m 46s\n",
      "560:\tlearn: 0.1291103\ttotal: 31m 35s\tremaining: 24m 43s\n",
      "561:\tlearn: 0.1290609\ttotal: 31m 38s\tremaining: 24m 39s\n",
      "562:\tlearn: 0.1290066\ttotal: 31m 41s\tremaining: 24m 36s\n",
      "563:\tlearn: 0.1289764\ttotal: 31m 45s\tremaining: 24m 32s\n",
      "564:\tlearn: 0.1289009\ttotal: 31m 48s\tremaining: 24m 29s\n",
      "565:\tlearn: 0.1288096\ttotal: 31m 52s\tremaining: 24m 26s\n",
      "566:\tlearn: 0.1287344\ttotal: 31m 55s\tremaining: 24m 22s\n",
      "567:\tlearn: 0.1286874\ttotal: 31m 58s\tremaining: 24m 19s\n",
      "568:\tlearn: 0.1286549\ttotal: 32m 2s\tremaining: 24m 15s\n",
      "569:\tlearn: 0.1286287\ttotal: 32m 5s\tremaining: 24m 12s\n",
      "570:\tlearn: 0.1285757\ttotal: 32m 8s\tremaining: 24m 9s\n",
      "571:\tlearn: 0.1285166\ttotal: 32m 12s\tremaining: 24m 5s\n",
      "572:\tlearn: 0.1284301\ttotal: 32m 15s\tremaining: 24m 2s\n",
      "573:\tlearn: 0.1283938\ttotal: 32m 18s\tremaining: 23m 58s\n",
      "574:\tlearn: 0.1283249\ttotal: 32m 22s\tremaining: 23m 55s\n",
      "575:\tlearn: 0.1282742\ttotal: 32m 25s\tremaining: 23m 52s\n",
      "576:\tlearn: 0.1282150\ttotal: 32m 28s\tremaining: 23m 48s\n",
      "577:\tlearn: 0.1281748\ttotal: 32m 32s\tremaining: 23m 45s\n",
      "578:\tlearn: 0.1281044\ttotal: 32m 35s\tremaining: 23m 41s\n",
      "579:\tlearn: 0.1280761\ttotal: 32m 38s\tremaining: 23m 38s\n",
      "580:\tlearn: 0.1280090\ttotal: 32m 42s\tremaining: 23m 35s\n",
      "581:\tlearn: 0.1279485\ttotal: 32m 46s\tremaining: 23m 32s\n",
      "582:\tlearn: 0.1279098\ttotal: 32m 49s\tremaining: 23m 28s\n",
      "583:\tlearn: 0.1278502\ttotal: 32m 52s\tremaining: 23m 25s\n",
      "584:\tlearn: 0.1277991\ttotal: 32m 56s\tremaining: 23m 22s\n",
      "585:\tlearn: 0.1277257\ttotal: 32m 59s\tremaining: 23m 18s\n",
      "586:\tlearn: 0.1276701\ttotal: 33m 3s\tremaining: 23m 15s\n",
      "587:\tlearn: 0.1276461\ttotal: 33m 6s\tremaining: 23m 11s\n",
      "588:\tlearn: 0.1276129\ttotal: 33m 9s\tremaining: 23m 8s\n",
      "589:\tlearn: 0.1275815\ttotal: 33m 12s\tremaining: 23m 4s\n",
      "590:\tlearn: 0.1275267\ttotal: 33m 16s\tremaining: 23m 1s\n",
      "591:\tlearn: 0.1274794\ttotal: 33m 19s\tremaining: 22m 58s\n",
      "592:\tlearn: 0.1274174\ttotal: 33m 23s\tremaining: 22m 54s\n",
      "593:\tlearn: 0.1273739\ttotal: 33m 26s\tremaining: 22m 51s\n",
      "594:\tlearn: 0.1273227\ttotal: 33m 29s\tremaining: 22m 48s\n",
      "595:\tlearn: 0.1272769\ttotal: 33m 33s\tremaining: 22m 44s\n",
      "596:\tlearn: 0.1272110\ttotal: 33m 36s\tremaining: 22m 41s\n",
      "597:\tlearn: 0.1271538\ttotal: 33m 39s\tremaining: 22m 37s\n",
      "598:\tlearn: 0.1270919\ttotal: 33m 43s\tremaining: 22m 34s\n",
      "599:\tlearn: 0.1270658\ttotal: 33m 46s\tremaining: 22m 31s\n",
      "600:\tlearn: 0.1270338\ttotal: 33m 50s\tremaining: 22m 27s\n",
      "601:\tlearn: 0.1269968\ttotal: 33m 53s\tremaining: 22m 24s\n",
      "602:\tlearn: 0.1269427\ttotal: 33m 56s\tremaining: 22m 20s\n",
      "603:\tlearn: 0.1268795\ttotal: 34m\tremaining: 22m 17s\n",
      "604:\tlearn: 0.1268263\ttotal: 34m 3s\tremaining: 22m 14s\n",
      "605:\tlearn: 0.1267724\ttotal: 34m 6s\tremaining: 22m 10s\n",
      "606:\tlearn: 0.1267446\ttotal: 34m 10s\tremaining: 22m 7s\n",
      "607:\tlearn: 0.1266699\ttotal: 34m 13s\tremaining: 22m 4s\n",
      "608:\tlearn: 0.1266078\ttotal: 34m 16s\tremaining: 22m\n",
      "609:\tlearn: 0.1265518\ttotal: 34m 20s\tremaining: 21m 57s\n",
      "610:\tlearn: 0.1265172\ttotal: 34m 23s\tremaining: 21m 53s\n",
      "611:\tlearn: 0.1264594\ttotal: 34m 27s\tremaining: 21m 50s\n",
      "612:\tlearn: 0.1263847\ttotal: 34m 30s\tremaining: 21m 47s\n",
      "613:\tlearn: 0.1263616\ttotal: 34m 33s\tremaining: 21m 43s\n",
      "614:\tlearn: 0.1262751\ttotal: 34m 37s\tremaining: 21m 40s\n",
      "615:\tlearn: 0.1262299\ttotal: 34m 40s\tremaining: 21m 37s\n",
      "616:\tlearn: 0.1262075\ttotal: 34m 44s\tremaining: 21m 33s\n",
      "617:\tlearn: 0.1261835\ttotal: 34m 47s\tremaining: 21m 30s\n",
      "618:\tlearn: 0.1261378\ttotal: 34m 50s\tremaining: 21m 26s\n",
      "619:\tlearn: 0.1260821\ttotal: 34m 54s\tremaining: 21m 23s\n",
      "620:\tlearn: 0.1260575\ttotal: 34m 57s\tremaining: 21m 20s\n",
      "621:\tlearn: 0.1260207\ttotal: 35m\tremaining: 21m 16s\n",
      "622:\tlearn: 0.1259216\ttotal: 35m 4s\tremaining: 21m 13s\n",
      "623:\tlearn: 0.1258846\ttotal: 35m 7s\tremaining: 21m 9s\n",
      "624:\tlearn: 0.1258227\ttotal: 35m 10s\tremaining: 21m 6s\n",
      "625:\tlearn: 0.1257890\ttotal: 35m 14s\tremaining: 21m 3s\n",
      "626:\tlearn: 0.1257298\ttotal: 35m 17s\tremaining: 20m 59s\n",
      "627:\tlearn: 0.1256552\ttotal: 35m 20s\tremaining: 20m 56s\n",
      "628:\tlearn: 0.1255912\ttotal: 35m 24s\tremaining: 20m 52s\n",
      "629:\tlearn: 0.1255688\ttotal: 35m 27s\tremaining: 20m 49s\n",
      "630:\tlearn: 0.1255387\ttotal: 35m 30s\tremaining: 20m 46s\n",
      "631:\tlearn: 0.1254737\ttotal: 35m 34s\tremaining: 20m 42s\n",
      "632:\tlearn: 0.1254514\ttotal: 35m 37s\tremaining: 20m 39s\n",
      "633:\tlearn: 0.1254054\ttotal: 35m 40s\tremaining: 20m 35s\n",
      "634:\tlearn: 0.1253559\ttotal: 35m 44s\tremaining: 20m 32s\n",
      "635:\tlearn: 0.1253251\ttotal: 35m 47s\tremaining: 20m 29s\n",
      "636:\tlearn: 0.1252930\ttotal: 35m 51s\tremaining: 20m 25s\n",
      "637:\tlearn: 0.1252711\ttotal: 35m 54s\tremaining: 20m 22s\n",
      "638:\tlearn: 0.1252157\ttotal: 35m 57s\tremaining: 20m 19s\n",
      "639:\tlearn: 0.1251621\ttotal: 36m 1s\tremaining: 20m 15s\n",
      "640:\tlearn: 0.1251133\ttotal: 36m 4s\tremaining: 20m 12s\n",
      "641:\tlearn: 0.1250583\ttotal: 36m 8s\tremaining: 20m 8s\n",
      "642:\tlearn: 0.1250268\ttotal: 36m 11s\tremaining: 20m 5s\n",
      "643:\tlearn: 0.1249661\ttotal: 36m 15s\tremaining: 20m 2s\n",
      "644:\tlearn: 0.1249449\ttotal: 36m 18s\tremaining: 19m 58s\n",
      "645:\tlearn: 0.1248742\ttotal: 36m 22s\tremaining: 19m 55s\n",
      "646:\tlearn: 0.1248156\ttotal: 36m 25s\tremaining: 19m 52s\n",
      "647:\tlearn: 0.1247762\ttotal: 36m 29s\tremaining: 19m 49s\n",
      "648:\tlearn: 0.1247396\ttotal: 36m 32s\tremaining: 19m 45s\n",
      "649:\tlearn: 0.1246896\ttotal: 36m 35s\tremaining: 19m 42s\n",
      "650:\tlearn: 0.1246693\ttotal: 36m 39s\tremaining: 19m 38s\n",
      "651:\tlearn: 0.1246490\ttotal: 36m 42s\tremaining: 19m 35s\n",
      "652:\tlearn: 0.1246166\ttotal: 36m 46s\tremaining: 19m 32s\n",
      "653:\tlearn: 0.1245554\ttotal: 36m 49s\tremaining: 19m 28s\n",
      "654:\tlearn: 0.1245362\ttotal: 36m 52s\tremaining: 19m 25s\n",
      "655:\tlearn: 0.1245108\ttotal: 36m 56s\tremaining: 19m 22s\n",
      "656:\tlearn: 0.1244628\ttotal: 36m 59s\tremaining: 19m 18s\n",
      "657:\tlearn: 0.1243752\ttotal: 37m 2s\tremaining: 19m 15s\n",
      "658:\tlearn: 0.1243303\ttotal: 37m 6s\tremaining: 19m 11s\n",
      "659:\tlearn: 0.1242818\ttotal: 37m 9s\tremaining: 19m 8s\n",
      "660:\tlearn: 0.1242387\ttotal: 37m 12s\tremaining: 19m 5s\n",
      "661:\tlearn: 0.1241896\ttotal: 37m 16s\tremaining: 19m 1s\n",
      "662:\tlearn: 0.1241365\ttotal: 37m 19s\tremaining: 18m 58s\n",
      "663:\tlearn: 0.1240891\ttotal: 37m 23s\tremaining: 18m 55s\n",
      "664:\tlearn: 0.1240293\ttotal: 37m 26s\tremaining: 18m 51s\n",
      "665:\tlearn: 0.1239825\ttotal: 37m 30s\tremaining: 18m 48s\n",
      "666:\tlearn: 0.1239409\ttotal: 37m 33s\tremaining: 18m 45s\n",
      "667:\tlearn: 0.1238931\ttotal: 37m 36s\tremaining: 18m 41s\n",
      "668:\tlearn: 0.1238740\ttotal: 37m 40s\tremaining: 18m 38s\n",
      "669:\tlearn: 0.1238233\ttotal: 37m 43s\tremaining: 18m 34s\n",
      "670:\tlearn: 0.1238015\ttotal: 37m 47s\tremaining: 18m 31s\n",
      "671:\tlearn: 0.1237672\ttotal: 37m 50s\tremaining: 18m 28s\n",
      "672:\tlearn: 0.1237165\ttotal: 37m 53s\tremaining: 18m 24s\n",
      "673:\tlearn: 0.1236972\ttotal: 37m 57s\tremaining: 18m 21s\n",
      "674:\tlearn: 0.1236416\ttotal: 38m\tremaining: 18m 18s\n",
      "675:\tlearn: 0.1235933\ttotal: 38m 3s\tremaining: 18m 14s\n",
      "676:\tlearn: 0.1235746\ttotal: 38m 7s\tremaining: 18m 11s\n",
      "677:\tlearn: 0.1235392\ttotal: 38m 10s\tremaining: 18m 7s\n",
      "678:\tlearn: 0.1234713\ttotal: 38m 13s\tremaining: 18m 4s\n",
      "679:\tlearn: 0.1234176\ttotal: 38m 17s\tremaining: 18m 1s\n",
      "680:\tlearn: 0.1233601\ttotal: 38m 20s\tremaining: 17m 57s\n",
      "681:\tlearn: 0.1233414\ttotal: 38m 23s\tremaining: 17m 54s\n",
      "682:\tlearn: 0.1233112\ttotal: 38m 27s\tremaining: 17m 50s\n",
      "683:\tlearn: 0.1232612\ttotal: 38m 30s\tremaining: 17m 47s\n",
      "684:\tlearn: 0.1232017\ttotal: 38m 33s\tremaining: 17m 44s\n",
      "685:\tlearn: 0.1231760\ttotal: 38m 37s\tremaining: 17m 40s\n",
      "686:\tlearn: 0.1231572\ttotal: 38m 40s\tremaining: 17m 37s\n",
      "687:\tlearn: 0.1231184\ttotal: 38m 43s\tremaining: 17m 33s\n",
      "688:\tlearn: 0.1230663\ttotal: 38m 47s\tremaining: 17m 30s\n",
      "689:\tlearn: 0.1230239\ttotal: 38m 50s\tremaining: 17m 27s\n",
      "690:\tlearn: 0.1229758\ttotal: 38m 53s\tremaining: 17m 23s\n",
      "691:\tlearn: 0.1229447\ttotal: 38m 57s\tremaining: 17m 20s\n",
      "692:\tlearn: 0.1228996\ttotal: 39m\tremaining: 17m 17s\n",
      "693:\tlearn: 0.1228531\ttotal: 39m 4s\tremaining: 17m 13s\n",
      "694:\tlearn: 0.1228169\ttotal: 39m 7s\tremaining: 17m 10s\n",
      "695:\tlearn: 0.1227400\ttotal: 39m 11s\tremaining: 17m 6s\n",
      "696:\tlearn: 0.1227221\ttotal: 39m 14s\tremaining: 17m 3s\n",
      "697:\tlearn: 0.1227005\ttotal: 39m 17s\tremaining: 17m\n",
      "698:\tlearn: 0.1226510\ttotal: 39m 21s\tremaining: 16m 56s\n",
      "699:\tlearn: 0.1226039\ttotal: 39m 24s\tremaining: 16m 53s\n",
      "700:\tlearn: 0.1225748\ttotal: 39m 27s\tremaining: 16m 50s\n",
      "701:\tlearn: 0.1225568\ttotal: 39m 31s\tremaining: 16m 46s\n",
      "702:\tlearn: 0.1225187\ttotal: 39m 34s\tremaining: 16m 43s\n",
      "703:\tlearn: 0.1224853\ttotal: 39m 38s\tremaining: 16m 39s\n",
      "704:\tlearn: 0.1224598\ttotal: 39m 41s\tremaining: 16m 36s\n",
      "705:\tlearn: 0.1224366\ttotal: 39m 44s\tremaining: 16m 33s\n",
      "706:\tlearn: 0.1223591\ttotal: 39m 48s\tremaining: 16m 29s\n",
      "707:\tlearn: 0.1223414\ttotal: 39m 51s\tremaining: 16m 26s\n",
      "708:\tlearn: 0.1223044\ttotal: 39m 55s\tremaining: 16m 23s\n",
      "709:\tlearn: 0.1222588\ttotal: 39m 58s\tremaining: 16m 19s\n",
      "710:\tlearn: 0.1222141\ttotal: 40m 1s\tremaining: 16m 16s\n",
      "711:\tlearn: 0.1221685\ttotal: 40m 5s\tremaining: 16m 13s\n",
      "712:\tlearn: 0.1221437\ttotal: 40m 8s\tremaining: 16m 9s\n",
      "713:\tlearn: 0.1220995\ttotal: 40m 12s\tremaining: 16m 6s\n",
      "714:\tlearn: 0.1220331\ttotal: 40m 15s\tremaining: 16m 2s\n",
      "715:\tlearn: 0.1220064\ttotal: 40m 18s\tremaining: 15m 59s\n",
      "716:\tlearn: 0.1219571\ttotal: 40m 22s\tremaining: 15m 56s\n",
      "717:\tlearn: 0.1219394\ttotal: 40m 25s\tremaining: 15m 52s\n",
      "718:\tlearn: 0.1219122\ttotal: 40m 29s\tremaining: 15m 49s\n",
      "719:\tlearn: 0.1218760\ttotal: 40m 32s\tremaining: 15m 45s\n",
      "720:\tlearn: 0.1218293\ttotal: 40m 35s\tremaining: 15m 42s\n",
      "721:\tlearn: 0.1218105\ttotal: 40m 39s\tremaining: 15m 39s\n",
      "722:\tlearn: 0.1217616\ttotal: 40m 42s\tremaining: 15m 35s\n",
      "723:\tlearn: 0.1217274\ttotal: 40m 46s\tremaining: 15m 32s\n",
      "724:\tlearn: 0.1216661\ttotal: 40m 49s\tremaining: 15m 29s\n",
      "725:\tlearn: 0.1216229\ttotal: 40m 53s\tremaining: 15m 25s\n",
      "726:\tlearn: 0.1215788\ttotal: 40m 56s\tremaining: 15m 22s\n",
      "727:\tlearn: 0.1215371\ttotal: 40m 59s\tremaining: 15m 19s\n",
      "728:\tlearn: 0.1215001\ttotal: 41m 3s\tremaining: 15m 15s\n",
      "729:\tlearn: 0.1214668\ttotal: 41m 6s\tremaining: 15m 12s\n",
      "730:\tlearn: 0.1214331\ttotal: 41m 9s\tremaining: 15m 8s\n",
      "731:\tlearn: 0.1214159\ttotal: 41m 13s\tremaining: 15m 5s\n",
      "732:\tlearn: 0.1213566\ttotal: 41m 16s\tremaining: 15m 2s\n",
      "733:\tlearn: 0.1213203\ttotal: 41m 20s\tremaining: 14m 58s\n",
      "734:\tlearn: 0.1212586\ttotal: 41m 23s\tremaining: 14m 55s\n",
      "735:\tlearn: 0.1212126\ttotal: 41m 27s\tremaining: 14m 52s\n",
      "736:\tlearn: 0.1211834\ttotal: 41m 30s\tremaining: 14m 48s\n",
      "737:\tlearn: 0.1211427\ttotal: 41m 34s\tremaining: 14m 45s\n",
      "738:\tlearn: 0.1211109\ttotal: 41m 37s\tremaining: 14m 42s\n",
      "739:\tlearn: 0.1210649\ttotal: 41m 40s\tremaining: 14m 38s\n",
      "740:\tlearn: 0.1210424\ttotal: 41m 44s\tremaining: 14m 35s\n",
      "741:\tlearn: 0.1209936\ttotal: 41m 47s\tremaining: 14m 32s\n",
      "742:\tlearn: 0.1209756\ttotal: 41m 51s\tremaining: 14m 28s\n",
      "743:\tlearn: 0.1209479\ttotal: 41m 54s\tremaining: 14m 25s\n",
      "744:\tlearn: 0.1208884\ttotal: 41m 58s\tremaining: 14m 21s\n",
      "745:\tlearn: 0.1208533\ttotal: 42m 1s\tremaining: 14m 18s\n",
      "746:\tlearn: 0.1208076\ttotal: 42m 5s\tremaining: 14m 15s\n",
      "747:\tlearn: 0.1207677\ttotal: 42m 8s\tremaining: 14m 11s\n",
      "748:\tlearn: 0.1207446\ttotal: 42m 11s\tremaining: 14m 8s\n",
      "749:\tlearn: 0.1207273\ttotal: 42m 15s\tremaining: 14m 5s\n",
      "750:\tlearn: 0.1206847\ttotal: 42m 18s\tremaining: 14m 1s\n",
      "751:\tlearn: 0.1206426\ttotal: 42m 22s\tremaining: 13m 58s\n",
      "752:\tlearn: 0.1206015\ttotal: 42m 25s\tremaining: 13m 54s\n",
      "753:\tlearn: 0.1205729\ttotal: 42m 28s\tremaining: 13m 51s\n",
      "754:\tlearn: 0.1205279\ttotal: 42m 32s\tremaining: 13m 48s\n",
      "755:\tlearn: 0.1204773\ttotal: 42m 35s\tremaining: 13m 44s\n",
      "756:\tlearn: 0.1204554\ttotal: 42m 38s\tremaining: 13m 41s\n",
      "757:\tlearn: 0.1204149\ttotal: 42m 42s\tremaining: 13m 38s\n",
      "758:\tlearn: 0.1203743\ttotal: 42m 45s\tremaining: 13m 34s\n",
      "759:\tlearn: 0.1203463\ttotal: 42m 49s\tremaining: 13m 31s\n",
      "760:\tlearn: 0.1202937\ttotal: 42m 52s\tremaining: 13m 27s\n",
      "761:\tlearn: 0.1202765\ttotal: 42m 55s\tremaining: 13m 24s\n",
      "762:\tlearn: 0.1202281\ttotal: 42m 59s\tremaining: 13m 21s\n",
      "763:\tlearn: 0.1201850\ttotal: 43m 2s\tremaining: 13m 17s\n",
      "764:\tlearn: 0.1201690\ttotal: 43m 6s\tremaining: 13m 14s\n",
      "765:\tlearn: 0.1201167\ttotal: 43m 9s\tremaining: 13m 11s\n",
      "766:\tlearn: 0.1200707\ttotal: 43m 13s\tremaining: 13m 7s\n",
      "767:\tlearn: 0.1200173\ttotal: 43m 16s\tremaining: 13m 4s\n",
      "768:\tlearn: 0.1199572\ttotal: 43m 20s\tremaining: 13m 1s\n",
      "769:\tlearn: 0.1198983\ttotal: 43m 23s\tremaining: 12m 57s\n",
      "770:\tlearn: 0.1198621\ttotal: 43m 27s\tremaining: 12m 54s\n",
      "771:\tlearn: 0.1197972\ttotal: 43m 30s\tremaining: 12m 50s\n",
      "772:\tlearn: 0.1197655\ttotal: 43m 33s\tremaining: 12m 47s\n",
      "773:\tlearn: 0.1197489\ttotal: 43m 37s\tremaining: 12m 44s\n",
      "774:\tlearn: 0.1197105\ttotal: 43m 40s\tremaining: 12m 40s\n",
      "775:\tlearn: 0.1196900\ttotal: 43m 43s\tremaining: 12m 37s\n",
      "776:\tlearn: 0.1196669\ttotal: 43m 47s\tremaining: 12m 33s\n",
      "777:\tlearn: 0.1196226\ttotal: 43m 50s\tremaining: 12m 30s\n",
      "778:\tlearn: 0.1195822\ttotal: 43m 53s\tremaining: 12m 27s\n",
      "779:\tlearn: 0.1195515\ttotal: 43m 57s\tremaining: 12m 23s\n",
      "780:\tlearn: 0.1194927\ttotal: 44m\tremaining: 12m 20s\n",
      "781:\tlearn: 0.1194411\ttotal: 44m 4s\tremaining: 12m 17s\n",
      "782:\tlearn: 0.1194255\ttotal: 44m 7s\tremaining: 12m 13s\n",
      "783:\tlearn: 0.1193822\ttotal: 44m 10s\tremaining: 12m 10s\n",
      "784:\tlearn: 0.1193480\ttotal: 44m 14s\tremaining: 12m 6s\n",
      "785:\tlearn: 0.1193226\ttotal: 44m 17s\tremaining: 12m 3s\n",
      "786:\tlearn: 0.1192887\ttotal: 44m 20s\tremaining: 12m\n",
      "787:\tlearn: 0.1192658\ttotal: 44m 23s\tremaining: 11m 56s\n",
      "788:\tlearn: 0.1192019\ttotal: 44m 27s\tremaining: 11m 53s\n",
      "789:\tlearn: 0.1191585\ttotal: 44m 30s\tremaining: 11m 49s\n",
      "790:\tlearn: 0.1190756\ttotal: 44m 34s\tremaining: 11m 46s\n",
      "791:\tlearn: 0.1190608\ttotal: 44m 37s\tremaining: 11m 43s\n",
      "792:\tlearn: 0.1190302\ttotal: 44m 40s\tremaining: 11m 39s\n",
      "793:\tlearn: 0.1190081\ttotal: 44m 44s\tremaining: 11m 36s\n",
      "794:\tlearn: 0.1189678\ttotal: 44m 47s\tremaining: 11m 33s\n",
      "795:\tlearn: 0.1189475\ttotal: 44m 51s\tremaining: 11m 29s\n",
      "796:\tlearn: 0.1189133\ttotal: 44m 54s\tremaining: 11m 26s\n",
      "797:\tlearn: 0.1188967\ttotal: 44m 57s\tremaining: 11m 22s\n",
      "798:\tlearn: 0.1188737\ttotal: 45m 1s\tremaining: 11m 19s\n",
      "799:\tlearn: 0.1188363\ttotal: 45m 4s\tremaining: 11m 16s\n",
      "800:\tlearn: 0.1188203\ttotal: 45m 7s\tremaining: 11m 12s\n",
      "801:\tlearn: 0.1187709\ttotal: 45m 11s\tremaining: 11m 9s\n",
      "802:\tlearn: 0.1187289\ttotal: 45m 14s\tremaining: 11m 5s\n",
      "803:\tlearn: 0.1187073\ttotal: 45m 17s\tremaining: 11m 2s\n",
      "804:\tlearn: 0.1186660\ttotal: 45m 21s\tremaining: 10m 59s\n",
      "805:\tlearn: 0.1186499\ttotal: 45m 24s\tremaining: 10m 55s\n",
      "806:\tlearn: 0.1185902\ttotal: 45m 27s\tremaining: 10m 52s\n",
      "807:\tlearn: 0.1185753\ttotal: 45m 31s\tremaining: 10m 48s\n",
      "808:\tlearn: 0.1185029\ttotal: 45m 34s\tremaining: 10m 45s\n",
      "809:\tlearn: 0.1184660\ttotal: 45m 37s\tremaining: 10m 42s\n",
      "810:\tlearn: 0.1184306\ttotal: 45m 41s\tremaining: 10m 38s\n",
      "811:\tlearn: 0.1184057\ttotal: 45m 44s\tremaining: 10m 35s\n",
      "812:\tlearn: 0.1183456\ttotal: 45m 47s\tremaining: 10m 32s\n",
      "813:\tlearn: 0.1183272\ttotal: 45m 51s\tremaining: 10m 28s\n",
      "814:\tlearn: 0.1182854\ttotal: 45m 54s\tremaining: 10m 25s\n",
      "815:\tlearn: 0.1182343\ttotal: 45m 58s\tremaining: 10m 21s\n",
      "816:\tlearn: 0.1181862\ttotal: 46m 1s\tremaining: 10m 18s\n",
      "817:\tlearn: 0.1181414\ttotal: 46m 5s\tremaining: 10m 15s\n",
      "818:\tlearn: 0.1180842\ttotal: 46m 8s\tremaining: 10m 11s\n",
      "819:\tlearn: 0.1180541\ttotal: 46m 11s\tremaining: 10m 8s\n",
      "820:\tlearn: 0.1180299\ttotal: 46m 15s\tremaining: 10m 5s\n",
      "821:\tlearn: 0.1180031\ttotal: 46m 18s\tremaining: 10m 1s\n",
      "822:\tlearn: 0.1179634\ttotal: 46m 21s\tremaining: 9m 58s\n",
      "823:\tlearn: 0.1179136\ttotal: 46m 25s\tremaining: 9m 54s\n",
      "824:\tlearn: 0.1178934\ttotal: 46m 28s\tremaining: 9m 51s\n",
      "825:\tlearn: 0.1178681\ttotal: 46m 31s\tremaining: 9m 48s\n",
      "826:\tlearn: 0.1178306\ttotal: 46m 35s\tremaining: 9m 44s\n",
      "827:\tlearn: 0.1177900\ttotal: 46m 38s\tremaining: 9m 41s\n",
      "828:\tlearn: 0.1177419\ttotal: 46m 41s\tremaining: 9m 37s\n",
      "829:\tlearn: 0.1177269\ttotal: 46m 45s\tremaining: 9m 34s\n",
      "830:\tlearn: 0.1176933\ttotal: 46m 48s\tremaining: 9m 31s\n",
      "831:\tlearn: 0.1176517\ttotal: 46m 52s\tremaining: 9m 27s\n",
      "832:\tlearn: 0.1176124\ttotal: 46m 55s\tremaining: 9m 24s\n",
      "833:\tlearn: 0.1175673\ttotal: 46m 58s\tremaining: 9m 21s\n",
      "834:\tlearn: 0.1175499\ttotal: 47m 2s\tremaining: 9m 17s\n",
      "835:\tlearn: 0.1174992\ttotal: 47m 5s\tremaining: 9m 14s\n",
      "836:\tlearn: 0.1174582\ttotal: 47m 8s\tremaining: 9m 10s\n",
      "837:\tlearn: 0.1173717\ttotal: 47m 12s\tremaining: 9m 7s\n",
      "838:\tlearn: 0.1173287\ttotal: 47m 15s\tremaining: 9m 4s\n",
      "839:\tlearn: 0.1172935\ttotal: 47m 19s\tremaining: 9m\n",
      "840:\tlearn: 0.1172731\ttotal: 47m 22s\tremaining: 8m 57s\n",
      "841:\tlearn: 0.1172152\ttotal: 47m 25s\tremaining: 8m 53s\n",
      "842:\tlearn: 0.1171687\ttotal: 47m 29s\tremaining: 8m 50s\n",
      "843:\tlearn: 0.1171540\ttotal: 47m 32s\tremaining: 8m 47s\n",
      "844:\tlearn: 0.1171394\ttotal: 47m 35s\tremaining: 8m 43s\n",
      "845:\tlearn: 0.1171103\ttotal: 47m 38s\tremaining: 8m 40s\n",
      "846:\tlearn: 0.1170887\ttotal: 47m 42s\tremaining: 8m 37s\n",
      "847:\tlearn: 0.1170487\ttotal: 47m 45s\tremaining: 8m 33s\n",
      "848:\tlearn: 0.1170005\ttotal: 47m 49s\tremaining: 8m 30s\n",
      "849:\tlearn: 0.1169570\ttotal: 47m 52s\tremaining: 8m 26s\n",
      "850:\tlearn: 0.1169296\ttotal: 47m 55s\tremaining: 8m 23s\n",
      "851:\tlearn: 0.1169052\ttotal: 47m 59s\tremaining: 8m 20s\n",
      "852:\tlearn: 0.1168637\ttotal: 48m 2s\tremaining: 8m 16s\n",
      "853:\tlearn: 0.1168312\ttotal: 48m 5s\tremaining: 8m 13s\n",
      "854:\tlearn: 0.1168106\ttotal: 48m 9s\tremaining: 8m 9s\n",
      "855:\tlearn: 0.1167634\ttotal: 48m 12s\tremaining: 8m 6s\n",
      "856:\tlearn: 0.1167349\ttotal: 48m 15s\tremaining: 8m 3s\n",
      "857:\tlearn: 0.1166987\ttotal: 48m 19s\tremaining: 7m 59s\n",
      "858:\tlearn: 0.1166596\ttotal: 48m 22s\tremaining: 7m 56s\n",
      "859:\tlearn: 0.1166442\ttotal: 48m 25s\tremaining: 7m 53s\n",
      "860:\tlearn: 0.1166212\ttotal: 48m 29s\tremaining: 7m 49s\n",
      "861:\tlearn: 0.1166071\ttotal: 48m 32s\tremaining: 7m 46s\n",
      "862:\tlearn: 0.1165927\ttotal: 48m 35s\tremaining: 7m 42s\n",
      "863:\tlearn: 0.1165429\ttotal: 48m 39s\tremaining: 7m 39s\n",
      "864:\tlearn: 0.1164974\ttotal: 48m 42s\tremaining: 7m 36s\n",
      "865:\tlearn: 0.1164574\ttotal: 48m 46s\tremaining: 7m 32s\n",
      "866:\tlearn: 0.1164217\ttotal: 48m 49s\tremaining: 7m 29s\n",
      "867:\tlearn: 0.1163904\ttotal: 48m 53s\tremaining: 7m 26s\n",
      "868:\tlearn: 0.1163415\ttotal: 48m 56s\tremaining: 7m 22s\n",
      "869:\tlearn: 0.1162966\ttotal: 49m\tremaining: 7m 19s\n",
      "870:\tlearn: 0.1162791\ttotal: 49m 3s\tremaining: 7m 15s\n",
      "871:\tlearn: 0.1162425\ttotal: 49m 6s\tremaining: 7m 12s\n",
      "872:\tlearn: 0.1162250\ttotal: 49m 10s\tremaining: 7m 9s\n",
      "873:\tlearn: 0.1161753\ttotal: 49m 13s\tremaining: 7m 5s\n",
      "874:\tlearn: 0.1161433\ttotal: 49m 16s\tremaining: 7m 2s\n",
      "875:\tlearn: 0.1161199\ttotal: 49m 20s\tremaining: 6m 59s\n",
      "876:\tlearn: 0.1160954\ttotal: 49m 23s\tremaining: 6m 55s\n",
      "877:\tlearn: 0.1160486\ttotal: 49m 27s\tremaining: 6m 52s\n",
      "878:\tlearn: 0.1160206\ttotal: 49m 30s\tremaining: 6m 48s\n",
      "879:\tlearn: 0.1160024\ttotal: 49m 33s\tremaining: 6m 45s\n",
      "880:\tlearn: 0.1159494\ttotal: 49m 37s\tremaining: 6m 42s\n",
      "881:\tlearn: 0.1159133\ttotal: 49m 40s\tremaining: 6m 38s\n",
      "882:\tlearn: 0.1158993\ttotal: 49m 43s\tremaining: 6m 35s\n",
      "883:\tlearn: 0.1158678\ttotal: 49m 47s\tremaining: 6m 32s\n",
      "884:\tlearn: 0.1158121\ttotal: 49m 50s\tremaining: 6m 28s\n",
      "885:\tlearn: 0.1157704\ttotal: 49m 54s\tremaining: 6m 25s\n",
      "886:\tlearn: 0.1157561\ttotal: 49m 57s\tremaining: 6m 21s\n",
      "887:\tlearn: 0.1157032\ttotal: 50m 1s\tremaining: 6m 18s\n",
      "888:\tlearn: 0.1156615\ttotal: 50m 4s\tremaining: 6m 15s\n",
      "889:\tlearn: 0.1156284\ttotal: 50m 7s\tremaining: 6m 11s\n",
      "890:\tlearn: 0.1156071\ttotal: 50m 11s\tremaining: 6m 8s\n",
      "891:\tlearn: 0.1155701\ttotal: 50m 14s\tremaining: 6m 5s\n",
      "892:\tlearn: 0.1155232\ttotal: 50m 18s\tremaining: 6m 1s\n",
      "893:\tlearn: 0.1154860\ttotal: 50m 21s\tremaining: 5m 58s\n",
      "894:\tlearn: 0.1154550\ttotal: 50m 24s\tremaining: 5m 54s\n",
      "895:\tlearn: 0.1154156\ttotal: 50m 28s\tremaining: 5m 51s\n",
      "896:\tlearn: 0.1153723\ttotal: 50m 31s\tremaining: 5m 48s\n",
      "897:\tlearn: 0.1153521\ttotal: 50m 35s\tremaining: 5m 44s\n",
      "898:\tlearn: 0.1153139\ttotal: 50m 38s\tremaining: 5m 41s\n",
      "899:\tlearn: 0.1152578\ttotal: 50m 42s\tremaining: 5m 38s\n",
      "900:\tlearn: 0.1152446\ttotal: 50m 45s\tremaining: 5m 34s\n",
      "901:\tlearn: 0.1151932\ttotal: 50m 48s\tremaining: 5m 31s\n",
      "902:\tlearn: 0.1151705\ttotal: 50m 52s\tremaining: 5m 27s\n",
      "903:\tlearn: 0.1151310\ttotal: 50m 55s\tremaining: 5m 24s\n",
      "904:\tlearn: 0.1150989\ttotal: 50m 59s\tremaining: 5m 21s\n",
      "905:\tlearn: 0.1150854\ttotal: 51m 2s\tremaining: 5m 17s\n",
      "906:\tlearn: 0.1150574\ttotal: 51m 5s\tremaining: 5m 14s\n",
      "907:\tlearn: 0.1150241\ttotal: 51m 9s\tremaining: 5m 10s\n",
      "908:\tlearn: 0.1149881\ttotal: 51m 12s\tremaining: 5m 7s\n",
      "909:\tlearn: 0.1149580\ttotal: 51m 16s\tremaining: 5m 4s\n",
      "910:\tlearn: 0.1149223\ttotal: 51m 19s\tremaining: 5m\n",
      "911:\tlearn: 0.1148913\ttotal: 51m 23s\tremaining: 4m 57s\n",
      "912:\tlearn: 0.1148714\ttotal: 51m 26s\tremaining: 4m 54s\n",
      "913:\tlearn: 0.1148581\ttotal: 51m 29s\tremaining: 4m 50s\n",
      "914:\tlearn: 0.1148239\ttotal: 51m 33s\tremaining: 4m 47s\n",
      "915:\tlearn: 0.1147957\ttotal: 51m 36s\tremaining: 4m 43s\n",
      "916:\tlearn: 0.1147728\ttotal: 51m 39s\tremaining: 4m 40s\n",
      "917:\tlearn: 0.1147392\ttotal: 51m 43s\tremaining: 4m 37s\n",
      "918:\tlearn: 0.1146983\ttotal: 51m 46s\tremaining: 4m 33s\n",
      "919:\tlearn: 0.1146814\ttotal: 51m 49s\tremaining: 4m 30s\n",
      "920:\tlearn: 0.1146681\ttotal: 51m 53s\tremaining: 4m 27s\n",
      "921:\tlearn: 0.1146192\ttotal: 51m 56s\tremaining: 4m 23s\n",
      "922:\tlearn: 0.1146052\ttotal: 52m\tremaining: 4m 20s\n",
      "923:\tlearn: 0.1145749\ttotal: 52m 3s\tremaining: 4m 16s\n",
      "924:\tlearn: 0.1145332\ttotal: 52m 6s\tremaining: 4m 13s\n",
      "925:\tlearn: 0.1145197\ttotal: 52m 10s\tremaining: 4m 10s\n",
      "926:\tlearn: 0.1145080\ttotal: 52m 13s\tremaining: 4m 6s\n",
      "927:\tlearn: 0.1144772\ttotal: 52m 17s\tremaining: 4m 3s\n",
      "928:\tlearn: 0.1144560\ttotal: 52m 20s\tremaining: 4m\n",
      "929:\tlearn: 0.1144123\ttotal: 52m 23s\tremaining: 3m 56s\n",
      "930:\tlearn: 0.1143940\ttotal: 52m 27s\tremaining: 3m 53s\n",
      "931:\tlearn: 0.1143702\ttotal: 52m 30s\tremaining: 3m 49s\n",
      "932:\tlearn: 0.1143268\ttotal: 52m 33s\tremaining: 3m 46s\n",
      "933:\tlearn: 0.1143004\ttotal: 52m 37s\tremaining: 3m 43s\n",
      "934:\tlearn: 0.1142717\ttotal: 52m 40s\tremaining: 3m 39s\n",
      "935:\tlearn: 0.1142295\ttotal: 52m 44s\tremaining: 3m 36s\n",
      "936:\tlearn: 0.1141889\ttotal: 52m 47s\tremaining: 3m 32s\n",
      "937:\tlearn: 0.1141618\ttotal: 52m 51s\tremaining: 3m 29s\n",
      "938:\tlearn: 0.1141379\ttotal: 52m 54s\tremaining: 3m 26s\n",
      "939:\tlearn: 0.1140694\ttotal: 52m 57s\tremaining: 3m 22s\n",
      "940:\tlearn: 0.1140470\ttotal: 53m 1s\tremaining: 3m 19s\n",
      "941:\tlearn: 0.1140070\ttotal: 53m 4s\tremaining: 3m 16s\n",
      "942:\tlearn: 0.1139655\ttotal: 53m 8s\tremaining: 3m 12s\n",
      "943:\tlearn: 0.1139396\ttotal: 53m 11s\tremaining: 3m 9s\n",
      "944:\tlearn: 0.1138904\ttotal: 53m 15s\tremaining: 3m 5s\n",
      "945:\tlearn: 0.1138586\ttotal: 53m 18s\tremaining: 3m 2s\n",
      "946:\tlearn: 0.1138109\ttotal: 53m 22s\tremaining: 2m 59s\n",
      "947:\tlearn: 0.1137808\ttotal: 53m 25s\tremaining: 2m 55s\n",
      "948:\tlearn: 0.1137520\ttotal: 53m 28s\tremaining: 2m 52s\n",
      "949:\tlearn: 0.1137351\ttotal: 53m 32s\tremaining: 2m 49s\n",
      "950:\tlearn: 0.1136706\ttotal: 53m 35s\tremaining: 2m 45s\n",
      "951:\tlearn: 0.1136511\ttotal: 53m 38s\tremaining: 2m 42s\n",
      "952:\tlearn: 0.1136012\ttotal: 53m 42s\tremaining: 2m 38s\n",
      "953:\tlearn: 0.1135659\ttotal: 53m 45s\tremaining: 2m 35s\n",
      "954:\tlearn: 0.1135298\ttotal: 53m 49s\tremaining: 2m 32s\n",
      "955:\tlearn: 0.1135067\ttotal: 53m 52s\tremaining: 2m 28s\n",
      "956:\tlearn: 0.1134713\ttotal: 53m 55s\tremaining: 2m 25s\n",
      "957:\tlearn: 0.1134310\ttotal: 53m 59s\tremaining: 2m 22s\n",
      "958:\tlearn: 0.1134173\ttotal: 54m 2s\tremaining: 2m 18s\n",
      "959:\tlearn: 0.1133771\ttotal: 54m 6s\tremaining: 2m 15s\n",
      "960:\tlearn: 0.1133592\ttotal: 54m 9s\tremaining: 2m 11s\n",
      "961:\tlearn: 0.1133162\ttotal: 54m 12s\tremaining: 2m 8s\n",
      "962:\tlearn: 0.1132760\ttotal: 54m 16s\tremaining: 2m 5s\n",
      "963:\tlearn: 0.1132492\ttotal: 54m 19s\tremaining: 2m 1s\n",
      "964:\tlearn: 0.1132034\ttotal: 54m 23s\tremaining: 1m 58s\n",
      "965:\tlearn: 0.1131910\ttotal: 54m 26s\tremaining: 1m 54s\n",
      "966:\tlearn: 0.1131575\ttotal: 54m 29s\tremaining: 1m 51s\n",
      "967:\tlearn: 0.1131026\ttotal: 54m 33s\tremaining: 1m 48s\n",
      "968:\tlearn: 0.1130604\ttotal: 54m 36s\tremaining: 1m 44s\n",
      "969:\tlearn: 0.1130417\ttotal: 54m 39s\tremaining: 1m 41s\n",
      "970:\tlearn: 0.1130140\ttotal: 54m 43s\tremaining: 1m 38s\n",
      "971:\tlearn: 0.1129733\ttotal: 54m 46s\tremaining: 1m 34s\n",
      "972:\tlearn: 0.1129608\ttotal: 54m 50s\tremaining: 1m 31s\n",
      "973:\tlearn: 0.1129232\ttotal: 54m 53s\tremaining: 1m 27s\n",
      "974:\tlearn: 0.1128896\ttotal: 54m 57s\tremaining: 1m 24s\n",
      "975:\tlearn: 0.1128715\ttotal: 55m\tremaining: 1m 21s\n",
      "976:\tlearn: 0.1128419\ttotal: 55m 3s\tremaining: 1m 17s\n",
      "977:\tlearn: 0.1128081\ttotal: 55m 7s\tremaining: 1m 14s\n",
      "978:\tlearn: 0.1127719\ttotal: 55m 10s\tremaining: 1m 11s\n",
      "979:\tlearn: 0.1127363\ttotal: 55m 14s\tremaining: 1m 7s\n",
      "980:\tlearn: 0.1126995\ttotal: 55m 17s\tremaining: 1m 4s\n",
      "981:\tlearn: 0.1126696\ttotal: 55m 20s\tremaining: 1m\n",
      "982:\tlearn: 0.1126430\ttotal: 55m 24s\tremaining: 57.5s\n",
      "983:\tlearn: 0.1125991\ttotal: 55m 27s\tremaining: 54.1s\n",
      "984:\tlearn: 0.1125815\ttotal: 55m 31s\tremaining: 50.7s\n",
      "985:\tlearn: 0.1125506\ttotal: 55m 34s\tremaining: 47.3s\n",
      "986:\tlearn: 0.1125153\ttotal: 55m 37s\tremaining: 44s\n",
      "987:\tlearn: 0.1124753\ttotal: 55m 41s\tremaining: 40.6s\n",
      "988:\tlearn: 0.1124583\ttotal: 55m 44s\tremaining: 37.2s\n",
      "989:\tlearn: 0.1124361\ttotal: 55m 47s\tremaining: 33.8s\n",
      "990:\tlearn: 0.1124106\ttotal: 55m 51s\tremaining: 30.4s\n",
      "991:\tlearn: 0.1123796\ttotal: 55m 54s\tremaining: 27.1s\n",
      "992:\tlearn: 0.1123673\ttotal: 55m 57s\tremaining: 23.7s\n",
      "993:\tlearn: 0.1123303\ttotal: 56m 1s\tremaining: 20.3s\n",
      "994:\tlearn: 0.1123183\ttotal: 56m 4s\tremaining: 16.9s\n",
      "995:\tlearn: 0.1122690\ttotal: 56m 8s\tremaining: 13.5s\n",
      "996:\tlearn: 0.1122376\ttotal: 56m 11s\tremaining: 10.1s\n",
      "997:\tlearn: 0.1122216\ttotal: 56m 14s\tremaining: 6.76s\n",
      "998:\tlearn: 0.1121816\ttotal: 56m 18s\tremaining: 3.38s\n",
      "999:\tlearn: 0.1121533\ttotal: 56m 21s\tremaining: 0us\n",
      "CPU times: user 55min 11s, sys: 1min 13s, total: 56min 24s\n",
      "Wall time: 56min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f4eb67cdf10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_catboost =  CatBoostClassifier(random_state=r)\n",
    "model_catboost.fit(tfidf_features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1 тестовой выборки для CatboostClassifier: 0.7519\n"
     ]
    }
   ],
   "source": [
    "predictions = model_catboost.predict(tfidf_features_test)\n",
    "f1_test = f1_score(target_test, predictions)\n",
    "print('Лучшее значение F1 тестовой выборки для CatboostClassifier: {:.4f}'.format(f1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = 0.7519"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Градиентный бустинг LightGBM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMClassifier(boosting_type='gbdt', random_state=r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CPU times: user 10min 4s, sys: 2.33 s, total: 10min 7s*  \n",
    "*Wall time: 10min 12s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 4s, sys: 2.33 s, total: 10min 7s\n",
      "Wall time: 10min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Обучим модель\n",
    "model_lgbm.fit(tfidf_features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1 тестовой выборки для LightGBMClassifier: 0.7451\n"
     ]
    }
   ],
   "source": [
    "predictions = model_lgbm.predict(tfidf_features_test)\n",
    "f1_test = f1_score(target_test, predictions)\n",
    "print('Лучшее значение F1 тестовой выборки для LightGBMClassifier: {:.4f}'.format(f1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = 0.7451"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем результаты со значениями метрики f1 на тестовых данных в Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "catboost               0.7519\n",
       "lgbmboost              0.7451\n",
       "logistic_regression    0.7318\n",
       "random_forest          0.6505\n",
       "decision_tree          0.5402\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['logistic_regression', 'decision_tree', 'random_forest', 'catboost','lgbmboost']\n",
    "table_f1 = pd.Series([model_1, model_2, model_3, model_4, model_5], index=index)\n",
    "table_f1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие результаты показала модель СatboostClassifier, значение метрики f1 которой составило 0.7519. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
